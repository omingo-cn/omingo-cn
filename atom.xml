<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>猿明园</title>
  
  <subtitle>笨鸟先飞，天道酬勤。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.omingo.com/"/>
  <updated>2020-08-21T05:50:38.923Z</updated>
  <id>https://www.omingo.com/</id>
  
  <author>
    <name>武继明</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>微服务化-数据库如何进行拆分</title>
    <link href="https://www.omingo.com/2020/08/21/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%8C%96-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%8B%86%E5%88%86/"/>
    <id>https://www.omingo.com/2020/08/21/微服务化-数据库如何进行拆分/</id>
    <published>2020-08-21T05:40:04.000Z</published>
    <updated>2020-08-21T05:50:38.923Z</updated>
    
    <content type="html"><![CDATA[<h1 id="微服务化-如何拆分数据库"><a href="#微服务化-如何拆分数据库" class="headerlink" title="微服务化-如何拆分数据库"></a>微服务化-如何拆分数据库</h1><p>在将单体应用拆分为较小服务的过程中，最难的部分就是单体服务数据库中的数据拆分。要进行这样的拆分，保证数据有一个全程唯一的写拷贝，并且遵循一系列步骤是很有帮助的。拆分步骤从对现有单体应用的逻辑分割开始：将服务行为拆分为一个单独的模块，然后把数据拆分到单独的数据表中。一系列动作之后，这些元素最终成为一个自治的新服务。</p><p>从单体应用向较小服务的迁移是目前的主流趋势。投资进行这样的迁移，其动力在于，围绕业务能力构建较小服务，能够提高开发者的生产力。团队一旦成为服务的主人，同时也就成为自身命运的主人，这就意味着可以不受系统中其他服务的限制，自由的对自有服务进行改善和升级。</p><p>这个转换过程之中最难的部分，就是从单体应用所持有的数据库中把新服务所属的数据拆分出来。如果从单体应用中拆分出来的逻辑部分仍然连接到同一个数据库，这种拆分无疑是比较简单的。但是这样一来，数据库就成为跨应用共享数据库，整个系统所呈现出的各自独立的分布式形态仅是徒有其表，在数据库层面，这依旧是一个紧耦合系统。真正独立的服务需要有独立的数据库——格式和数据都专属于服务。</p><p>本文中要讲述一系列步骤组成的一个解构模式，用来在最小化业务中断的前提下，从单体应用中拆出富数据服务。</p><h2 id="服务拆分过程的指导原则"><a href="#服务拆分过程的指导原则" class="headerlink" title="服务拆分过程的指导原则"></a>服务拆分过程的指导原则</h2><p>深入探讨之前，我想首先介绍两个对于服务拆分具有重要指导意义的基本原则。这两条原则能把从单体应用到多服务的拆分过程变得更加平滑，也更加安全。</p><h3 id="整个迁移过程中，数据保持有单一的写拷贝"><a href="#整个迁移过程中，数据保持有单一的写拷贝" class="headerlink" title="整个迁移过程中，数据保持有单一的写拷贝"></a>整个迁移过程中，数据保持有单一的写拷贝</h3><p>在转移过程中，我们应该保证待迁出服务的数据始终有一个单独的写拷贝。如果出现了多个可写拷贝，就会出现写冲突的风险。当多个客户端同时写入同一块数据的时候，写冲突就会出现。写冲突的应对是比较复杂的——需要选择一个处理模式，并进行相应的处理。例如以最后写入为准的话，会给部分客户端带来意料之外的后果，同时还要通知写入失败的客户端进行相应的纠错处理。这样的逻辑无疑是比较复杂的，应该尽量避免。</p><p>这里的服务拆分模式会保证在服务拆分过程中的任意时间点上，都保持唯一的可写副本，从而避免写冲突造成的复杂性。</p><h3 id="遵循“架构演进原子化”的原则"><a href="#遵循“架构演进原子化”的原则" class="headerlink" title="遵循“架构演进原子化”的原则"></a>遵循“架构演进原子化”的原则</h3><p>代表在架构迁移过程中使用一系列原子化步骤。这些步骤完成以后，架构就完成了承诺的升级。如果这些步骤没有完全执行，那么这一架构的状态会比初始状态更加糟糕。例如决定分拆一个服务，结果最后只拆分了逻辑，没能拆分数据，这样收获的是一个数据库层耦合的状态，这一状态依然会导致开发和运行时的紧密耦合。实际上对比开始分拆之前，系统变得更加复杂，开发和除错的难度也随之增加了。</p><p>下面讲到的模式中，我们建议完成其中的所有步骤来完成拆分工作。服务分拆过程之中的最大障碍并非来自技术，而是如何让既有的单体应用客户迁移到新的服务之中去。我们将在第五步讨论这一话题。</p><h2 id="服务拆分的步骤"><a href="#服务拆分的步骤" class="headerlink" title="服务拆分的步骤"></a>服务拆分的步骤</h2><p>现在让我们进入实际的服务拆分模式之中。为了方便讲述和操作，我们会做一个例子，来解释服务拆分的具体过程。</p><p>假设有个单体形态的商品信息系统，用来给我们的电商平台提供商品信息。经过一段时间的发展和演进，这一系统的服务范围不仅包含了商品名称、类目名称等核心信息和相关逻辑，同时还包含了商品定价方面的逻辑和数据。商品核心信息和价格信息之间并没有清晰的边界。</p><p>另外系统的变动频率来看，价格方面的系统变更频率要远高于核心信息部分。数据访问的模式也是各有千秋。商品的价格信息变动比核心商品属性同样要快得多。这样一来，把价格部分分拆到单体应用之外，形成一个单独的服务就是个非常有吸引力的想法了。</p><p>同商品核心信息相比，价格信息更加适合分拆，这是因为在原有应用的依赖体系中，定价功能是一个叶子节点。核心商品信息被很多其他功能所依赖，例如商品库存、市场等很多功能。如果将核心信息功能分拆出来，就意味着同时要触动很多相关系统，这会产生很大的风险。因此应该在功能依赖图中选择一个有业务价值的叶子节点作为开始。</p><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821120535723_752202678.png"><blockquote><p>图 1：类目系统中包含了核心信息和价格信息两部分的逻辑和数据。有两个客户端——Web 应用和 iOS app。</p></blockquote><h3 id="代码的初始状态"><a href="#代码的初始状态" class="headerlink" title="代码的初始状态"></a>代码的初始状态</h3><p>下面是商品系统的现有代码。很明显的，这些代码不具备真实的复杂度。然而用来演示拆分富数据服务的重构过程，其复杂度还是足够的。下面的内容中会看到每个步骤中代码的变化过程。</p><p>这段代码中包含了一个 <code>CatalogService</code> 接口，用于给客户端提供服务。它使用一个 <code>productRepository</code> 类和数据库进行交互，用于数据的获取和存储。<code>Product</code> 是一个（Dumb data class）哑类，包含了商品信息。哑类设计是一种反模式设计，不过这不是本文的重点。<code>Sku</code>、<code>Price</code> 以及 <code>CategoryPriceRange</code> 几个类都是比较边缘的小类。</p><pre><code class="java">class CatalogService…  public Sku searchProduct(String searchString) {      return productRepository.searchProduct(searchString);  }  public Price getPriceFor(Sku sku) {      Product product = productRepository.queryProduct(sku);      return calculatePriceFor(product);  }  private Price calculatePriceFor(Product product) {      if(product.isOnSale()) return product.getSalePrice();      return product.getOriginalPrice();  }  public CategoryPriceRange getPriceRangeFor(Category category) {      List&lt;Product&gt; products = productRepository.findProductsFor(category);      Price maxPrice = null;      Price minPrice = null;      for (Product product : products) {          if (product.isActive()) {              Price productPrice = calculatePriceFor(product);              if (maxPrice == null || productPrice.isGreaterThan(maxPrice)) {                  maxPrice = productPrice;              }              if (minPrice == null || productPrice.isLesserThan(minPrice)) {                  minPrice = productPrice;              }          }      }      return new CategoryPriceRange(category, minPrice, maxPrice);  }  public void updateIsOnSaleFor(Sku sku) {      final Product product = productRepository.queryProduct(sku);      product.setOnSale(true);      productRepository.save(product);  }</code></pre><p>下面就开始从商品单体应用中抽取 “Product pricing” 服务的第一步。</p><h4 id="步骤-1：识别新服务涉及到的逻辑和数据"><a href="#步骤-1：识别新服务涉及到的逻辑和数据" class="headerlink" title="步骤 1：识别新服务涉及到的逻辑和数据"></a>步骤 1：识别新服务涉及到的逻辑和数据</h4><p>第一个步骤中，需要对商品应用中的商品定价服务所包含的逻辑和数据进行识别。我们的商品应用中包含了一个 <code>Products</code> 数据表，其中包含了<code>name</code>、<code>SKU</code>、<code>category_name</code> 以及<code>is_active</code> 标志（用于表示该商品是否有效或者已经弃用）等核心数据。每个商品都属于一个商品类目，类目就是一组商品。例如“男式衬衫”类目包含了花衬衫和晚礼服衬衫等商品。同时这个应用中还有一些核心的商品逻辑，例如根据名称进行商品搜索等。</p><p><code>Products</code> 数据表还有一些定价相关的字段，例如 <code>original_price</code>、<code>sale_price</code> 以及<code>is_on_sale</code> 标志（用于标识该商品是否在售）。商品应用中包含了一些定价方面的功能，比如计算商品价格、更新 <code>is_on_sale</code> 标志。另外还有一个纠结的功能，就是获取一个类目的价格区间，它主要属于定价范畴，但是也要涉及一些商品的核心功能。<br><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821120929358_1234573143.png"></p><blockquote><p>图 2：绿色部分是商品的核心逻辑和数据，蓝色部分是定价方面的逻辑和数据。 </p></blockquote><p>接下来重新贴一下上面的代码，代码没有发生变化，核心部分加入了注释（原文用蓝绿标识，MD 格式限制，只能用注释代替）。</p><pre><code class="java">  // 搜索商品  public Sku searchProduct(String searchString) {      return productRepository.searchProduct(searchString);  }  public Price getPriceFor(Sku sku) {      Product product = productRepository.queryProduct(sku);      return calculatePriceFor(product);  }  private Price calculatePriceFor(Product product) {      if(product.isOnSale()) return product.getSalePrice();      return product.getOriginalPrice();  }  public CategoryPriceRange getPriceRangeFor(Category category) {      // 搜索指定类目中的商品      List&lt;Product&gt; products = productRepository.findProductsFor(category);      Price maxPrice = null;      Price minPrice = null;      for (Product product : products) {          // 商品是否可用          if (product.isActive()) {              Price productPrice = calculatePriceFor(product);              if (maxPrice == null || productPrice.isGreaterThan(maxPrice)) {                  maxPrice = productPrice;              }              if (minPrice == null || productPrice.isLesserThan(minPrice)) {                  minPrice = productPrice;              }          }      }      return new CategoryPriceRange(category, minPrice, maxPrice);  }  public void updateIsOnSaleFor(Sku sku) {      final Product product = productRepository.queryProduct(sku);      product.setOnSale(true);      productRepository.save(product);  }</code></pre><h4 id="步骤-2：在单体应用中对新服务进行逻辑上的拆分"><a href="#步骤-2：在单体应用中对新服务进行逻辑上的拆分" class="headerlink" title="步骤 2：在单体应用中对新服务进行逻辑上的拆分"></a>步骤 2：在单体应用中对新服务进行逻辑上的拆分</h4><p>第二三步是关于逻辑拆分的，要在商品应用持续运作的情况下，对商品定价服务的逻辑和数据进行逻辑上的分割。简而言之就是在创建新服务之前，首先在单体应用中，对产品的定价数据和逻辑进行隔离。这样做的好处在于，由于还在同一个代码库中，如果定错了产品定价服务所包含的逻辑或者数据边界，纠正这一错误所需的重构工作，相对于拆分为新服务之后，会比较简单一些。<br>第二步的一部分，我们要创建两个服务类，用来封装不同对象的逻辑：</p><ul><li>商品核心类：<code>CoreProductService</code></li><li>商品定价类：<code>ProductPricingService</code></li></ul><p>这些服务类会和我们的“物理”类一一对应，也就是后面看到的商品定价和商品核心。我们还会创建独立的存储类—— <code>ProductPriceRepository</code> 用来访问产品定价数据，以及 <code>CoreProductRepository</code> 用来访问核心商品数据，这两种数据目前都存储在 <code>Products</code> 数据表中。</p><p>这部分工作中，需要时刻注意的关键一点是 <code>ProductPricingService</code> 或者 <code>ProductPriceRepository</code> 不应该访问 <code>Products</code> 表中的商品核心信息，而应该通过 <code>CoreProductService</code> 类来进行所有商品核心信息相关的访问。下文中会看到对 <code>getPriceRangeFor</code> 方法进行重构的例子。</p><p>不允许存在商品核心信息和商品定价信息之间的表关联。类似的，数据库中也不该有核心商品信息和商品定价信息之间的硬约束。所有的 <strong>JOIN</strong> 和 约束都应该从数据库层转移到逻辑层。不过知易行难是个普遍规律，数据库的拆分过程中，这一点是个难度和必要性都很高的任务。</p><p>不难看出，商品核心和商品定价之间是有一个共享的标识符的——两个系统中，<code>SKU</code> 都能能够作为商品的唯一标识。这种跨系统标识符会用在跨系统的通信过程之中，它的重要性显而易见，因此必须慎重选择。只能够有一个系统独立掌握这一数据。所有其它服务都只能对其进行只读的引用——在这些服务的视角中，标识符是固定不变的。标识符所属的实体，其生命周期的管理者，是最适合作为该标识符的属主的。例如我们的案例中，商品核心信息服务掌控着商品的生命周期，因此 <code>SKU</code> 标识符也应该由这一部分进行管理。<br><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821121503545_1463964774.png"></p><blockquote><p>图 3：商品核心信息逻辑和商品定价逻辑的拆分，此时商品定价逻辑仍然连接在同一个商品数据表上。</p></blockquote><p>下面是重构的代码。你会看到新建了 <code>ProductPricingService</code> 用来负责定价相关的逻辑。另外还定义了 <code>productPriceRepository</code> 用来访问 <code>Products</code> 表中的定价相关数据。现在的 <code>Product</code> 数据类被分为了 <code>CoreProduct</code> 和 <code>ProductPrice</code> 两个类，分别用户处理商品核心信息和商品定价信息。</p><pre><code class="java">class ProductPricingService…  public Price getPriceFor(Sku sku) {      ProductPrice productPrice = productPriceRepository.getPriceFor(sku);      return calculatePriceFor(productPrice);  }  private Price calculatePriceFor(ProductPrice productPrice) {      if(productPrice.isOnSale()) return productPrice.getSalePrice();      return productPrice.getOriginalPrice();  }</code></pre><p>获取指定类目的价格范围，这一功能相对复杂。这是因为它需要获取类目中的商品列表，而这一操作是属于商品核心部分的。<code>getPriceRangeFor</code> 方法首先要调用 <code>coreProductService</code> 的 <code>getActiveProductsFor</code> 方法来获取类目中的有效商品列表。前面提到过 <code>is_active</code> 是商品核心的属性，因此将 <code>isActive</code> 检查也放到 coreProductService 之中。</p><pre><code class="java">class ProductPricingService…  public CategoryPriceRange getPriceRangeFor(Category category) {      // 获取商品列表      List&lt;CoreProduct&gt; products = coreProductService.getActiveProductsFor(category);      // 根据商品列表获取价格      List&lt;ProductPrice&gt; productPrices = productPriceRepository.getProductPricesFor(mapCoreProductToSku(products));      Price maxPrice = null;      Price minPrice = null;      for (ProductPrice productPrice : productPrices) {              Price currentProductPrice = calculatePriceFor(productPrice);              if (maxPrice == null || currentProductPrice.isGreaterThan(maxPrice)) {                  maxPrice = currentProductPrice;              }              if (minPrice == null || currentProductPrice.isLesserThan(minPrice)) {                  minPrice = currentProductPrice;              }      }      return new CategoryPriceRange(category, minPrice, maxPrice);  }  private List&lt;Sku&gt; mapCoreProductToSku(List&lt;CoreProduct&gt; coreProducts) {      return coreProducts.stream().map(p -&gt; p.getSku()).collect(Collectors.toList());  }</code></pre><p><code>getActiveProductsFor</code> 方法获取指定类目商品列表的代码大致如下 :</p><pre><code class="java">class CoreProductService…  public List&lt;CoreProduct&gt; getActiveProductsFor(Category category) {      // 获取类目下的商品列表      List&lt;CoreProduct&gt; productsForCategory = coreProductRepository.getProductsFor(category);      // 只返回 is_active 的商品列表      return filterActiveProducts(productsForCategory);  }  // 根据 is_active 进行过滤  private List&lt;CoreProduct&gt; filterActiveProducts(List&lt;CoreProduct&gt; products) {      return products.stream().filter(p -&gt; p.isActive()).collect(Collectors.toList());  }</code></pre><p>在本例中，我们把 <code>isActive</code> 的检查保留在了服务中，但是把它转移到数据库查询之中也是很容易的。实际上将功能拆分为多个服务之后，很容易发现这些将逻辑下放到查询层从而提高运行效率的机会。</p><p><code>updateIsOnSale</code> 功能非常直接，可以进行如下重构：</p><pre><code class="java">class ProductPricingService…  public void updateIsOnSaleFor(Sku sku) {      final ProductPrice productPrice = productPriceRepository.getPriceFor(sku);      productPrice.setOnSale(true);      productPriceRepository.save(productPrice);</code></pre><p><code>searchProduct</code> 方法指向新建的 <code>coreProductRepository</code>，用于商品搜索。</p><pre><code class="java">class CoreProductService…  public Sku searchProduct(String searchString) {      return coreProductRepository.searchProduct(searchString);  }</code></pre><p>原单体应用的顶层接口是 <code>CatalogService</code>，这里也需要进行重构，对不同的功能调用，要委托给不同的服务——<code>CoreProductService</code> 和 <code>ProductPricingService</code>。这个过程很重要，它保障了现有的客户端和服务端之间的契约。</p><p><code>searchProduct</code> 方法委托给了 <code>CoreProductService</code>：</p><pre><code class="java">class CatalogService…  public Sku searchProduct(String searchString) {      return coreProductService.searchProduct(searchString);  }</code></pre><p>定价相关的方法则委托给了 <code>productPricingService</code>：</p><pre><code class="java">class CatalogService…  public Price getPriceFor(Sku sku) {      return productPricingService.getPriceFor(sku);  }  public CategoryPriceRange getPriceRangeFor(Category category) {      return productPricingService.getPriceRangeFor(category);  }  public void updateIsOnSaleFor(Sku sku) {      productPricingService.updateIsOnSaleFor(sku);  }</code></pre><h4 id="步骤-3：为身处单体服务当中的新服务创建数据表"><a href="#步骤-3：为身处单体服务当中的新服务创建数据表" class="headerlink" title="步骤 3：为身处单体服务当中的新服务创建数据表"></a>步骤 3：为身处单体服务当中的新服务创建数据表</h4><p>这个步骤中，我们要把定价相关的数据拆分到一个新的数据表中——<code>Productprices</code>。这一步骤的最后，商品定价逻辑应该访问 <code>ProductPrices</code> 数据表，而不再是 <code>Products</code> 表。对任何 <code>Products</code> 数据表中关于商品核心信息的请求，都应该从商品核心逻辑层中获取。这个步骤中，除了 <code>productPricingRepository</code> 类之外，所有其他类，尤其是服务类的代码都不应被触及。</p><p>这个步骤中要把一个数据表一分为二，因此很重要的一项工作就是 <code>Products</code> 表到 <code>ProductPrices</code> 表的数据迁移。</p><p>在本步骤最后，可能会觉察到新服务可能会对整体系统造成一些影响，尤其是性能方面。逻辑层中的内存内数据 <strong>Join</strong> 的性能影响是显而易见的。在我们的例子中，<code>getPriceRangeFor</code> 方法就在商品核心信息和商品定价信息之间进行了一次连接。在业务代码中完成数据连接相对于数据库来说，始终是一种更大开销的操作，这也是数据解耦的代价之一。如果在这一阶段中的性能损失非常严重，那么把数据迁回的话，情况会变得更糟糕，更不要提将服务进行物理拆分之后了。如果性能需求（以及可能存在的受这次重构影响的其他需求）无法满足，那么很可能需要重新思考一下服务边界的问题。至少在目前阶段里，Web 应用和 iOS 还都保持良好，这是因为我们没有修改任何和客户端发生交互的部分。这一步骤的另一个功能，就是进行了一次物美价廉的测试。<br><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821122725122_1150861971.png"></p><blockquote><p>图 4：拆分成两块：商品核心的数据和逻辑，商品定价的数据和逻辑。</p></blockquote><h4 id="步骤-4：创建新的服务，并且访问单体应用的原有数据库"><a href="#步骤-4：创建新的服务，并且访问单体应用的原有数据库" class="headerlink" title="步骤 4：创建新的服务，并且访问单体应用的原有数据库"></a>步骤 4：创建新的服务，并且访问单体应用的原有数据库</h4><p>这个步骤中就要开始给商品定价的逻辑建立新的“物理”服务了，新的服务以 <code>ProductPricingService</code> 为基础，但是数据库依旧沿用单体应用所持有的 <code>ProductPrice</code> 数据表。注意到了这一步，<code>ProductPricingService</code> 调用 <code>CoreProductService</code> 就会变为网络调用了，这种变化不仅会对性能造成影响，还需要增加对超时等网络调用特有问题的处理。</p><p>这也是一个业务抽象验证的好机会，这里可以看到新的商品定价服务的建模到底针对的是技术方案还是业务需求。例如当业务用户在执行 <code>updateIsOnSale</code> 时，他的真正需要是在系统中给特定商品创建一个“促销”。下面的代码就是重构以后的 <code>updateIsOnSaleFor</code>。我们响应业务需求，对功能进行了改进，在参数中加入了促销价格，这在以前是没有的。这还是一个将从前流落到客户端的逻辑重新归纳到服务级别的好机会。在客户端的角度来看，这明显是一个有利的变更。</p><pre><code class="java">class ProductPricingService…  public void createPromotion(Promotion promotion) {      final ProductPrice productPrice = productPriceRepository.getPriceFor(promotion.getSku());      productPrice.setOnSale(true);      productPrice.setSalePrice(promotion.getPrice());      productPriceRepository.save(productPrice);  }</code></pre><p>当然这些重构并非天马行空任意施为的，其中一个重要限制就是不能修改表结构以及表数据的语义，否则可能会破坏掉单体应用中的已有功能。服务拆分大功告成之后（步骤 9），就可以对自己的数据库以及代码为所欲为了。</p><p>你可能想要在进行客户端迁移之前进行这一变更，尤其是在大型组织机构中，要让大量不同的服务消费者在限定时间内进行迁移，这一过程需要消耗大量的时间和金钱。下一步中会详细讨论这一问题。新的定价服务可以安全的部署到生产环境中进行测试——反正没有客户端在使用这一服务。同样这里对客户端没有任何变更，例如本例中的 Web 应用和 iOS App 都没有受到任何影响。</p><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821122927007_556836816.png"><blockquote><p>图 5：商品定价服务分拆成了新的“物理”服务，新服务在数据方面要依赖单体应用中的 <code>ProductPrices</code> 表，而功能上则要依赖于单体应用中的核心产品功能。</p></blockquote><h4 id="步骤-5：让客户端使用新的服务"><a href="#步骤-5：让客户端使用新的服务" class="headerlink" title="步骤 5：让客户端使用新的服务"></a>步骤 5：让客户端使用新的服务</h4><p>这个步骤里，单体服务的客户端中涉及商品定价的部分就需要转移到新的服务上了。这一阶段的工作有两个依赖项：</p><ul><li>新旧结构中有多少接口发生了变更。</li><li>在组织视角，有多少客户端团队需要及时进行迁移。</li></ul><p>这一步骤启动以后，整体架构可能会处于一个中间状态：新旧服务都有客户端在访问。这种状况实际上是比初始状态更加糟糕的。这就是前面讨论过的原子化的架构演进原则的必要性。在迁移开始之前，要获得组织的确认，所有新功能的相关客户端能够按时完成迁移。在架构处于半完成状态期间，是非常容易受到其他的所谓高优先级问题的干扰的。</p><p>好消息是，并非所有客户端都需要同时进行迁移。然而在进行下一步之前，完成所有的客户端改造是必要的。可以设置一些服务级的监控机制来监视定价相关的方法，来识别没有完成相关变更的客户端。</p><p>理论上可以在客户端完成改造之前开始一些下一步的工作，尤其是下一步中包含了创建定价数据库的操作，但是为了工作的简化，我还是建议尽量按照顺序完成步骤。</p><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821133223153_1665566047.png"><blockquote><p>图 6：要使用定价功能的客户端已经迁移到新的定价服务。</p></blockquote><h4 id="步骤-6：为新服务创建数据库"><a href="#步骤-6：为新服务创建数据库" class="headerlink" title="步骤 6：为新服务创建数据库"></a>步骤 6：为新服务创建数据库</h4><p>这一步相对简单，从单体应用的数据表中进行镜像，创建新的定价数据库。这一过程中有个很大的诱惑就是：既然代码已经进行了重构，干脆也对定价数据库进行一次重构吧。但是数据结构的变化会提高后面将要进行的数据迁移过程的难度。这还意味着新的新的定价服务同时要支持两套不同的结构。我还是建议让事情简单一点：首先分离定价服务（终结所有本文中提到的步骤），然后单独对定价服务进行重构。定价数据库的隔离一旦完成，对数据库的修改就很容易了，毕竟没有客户端会直接访问数据库。<br><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821133337609_532624610.png"></p><blockquote><p>图 7：独立的定价数据库已经建立。</p></blockquote><h4 id="步骤-7：同步数据到新数据库"><a href="#步骤-7：同步数据到新数据库" class="headerlink" title="步骤 7：同步数据到新数据库"></a>步骤 7：同步数据到新数据库</h4><p>这一步需要从单体应用的数据库中把定价表的数据同步给新的定价数据库。如果结构没有发生变化，那么这个同步过程是非常简单明了的。基本上相当于把定价数据库设置为原有数据库的只读副本过程（仅涉及到定价相关的数据表）。这样也能保障新的定价数据库的及时性。</p><p>迁移完成后，就可以准备在下个步骤中，让独立的定价服务来访问新的定价数据库了。<br><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821133431892_1930230827.png"></p><blockquote><p>图 8：从旧数据库中同步定价数据表给新建的定价数据库。</p></blockquote><h4 id="步骤-8：让新服务使用新数据库"><a href="#步骤-8：让新服务使用新数据库" class="headerlink" title="步骤 8：让新服务使用新数据库"></a>步骤 8：让新服务使用新数据库</h4><p>开始之前，必须要保证所有使用定价功能的客户端迁移到新的服务上去。如果没有，就面临着写入冲突的风险，这也是前面强调“唯一写拷贝”原则的理由。所有客户端都迁移到新的服务端之后，就需要将定价服务指向新的数据库了。简单说来就是把数据库连接进行一次切换。</p><p>这样做的一个好处就是在出现问题的时候，还有机会轻松的迁移回到原数据库。有一种常见问题就是，新数据库中缺乏一些新服务所必须的数据表或者字段。这是步骤一中的失误所产生的后果。有可能是缺少了一些必要的引用数据，比如货币代码。成功解决这些问题之后，就可以进入下一步了。</p><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821133536686_1995925764.png"><blockquote><p>图 9：指向定价数据库的定价服务。</p></blockquote><h4 id="步骤-9：从单体应用中删除新服务相关的逻辑和数据"><a href="#步骤-9：从单体应用中删除新服务相关的逻辑和数据" class="headerlink" title="步骤 9：从单体应用中删除新服务相关的逻辑和数据"></a>步骤 9：从单体应用中删除新服务相关的逻辑和数据</h4><p> 这里就要从原有应用中删除定价功能相关的逻辑和数据库了。很多团队会在数据库中留着旧数据，仅仅是因为担心“万一有用呢？”。进行一次全库备份可能有助于缓解这种恐惧。</p><p>现在 <code>CatalogService</code> 的所有功能都委托给了对 <code>CoreProductService</code> 服务的调用，顺理成章地，我们就可以移除这一中间层，让客户直接调用 <code>CoreProductService</code> 服务了。</p><img src="/2020/08/21/微服务化-数据库如何进行拆分/20200821133700116_1081728115.png"><blockquote><p>图 10：商品核心只有商品核心的相关逻辑和数据；商品定价服务持有定价的逻辑和数据，二者仅在逻辑层面进行交互。</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>大功告成！我们成功的把数据的服务从单体应用中解放了出来。</p><p>第一次进行这项工作时，会有很多痛苦，也会受到很多教训，这都会让你的下一次拆分更加顺利。初次拆分过程中，不管面对多大诱惑，都最好不要尝试合并这些步骤。一次只进行一步，让整个工作流程更少悬念，更多的安全感和可预测性。在成功掌握这一模式之后，就可以根据自身所学对这些步骤进行优化了。</p><p>祝你好运！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;微服务化-如何拆分数据库&quot;&gt;&lt;a href=&quot;#微服务化-如何拆分数据库&quot; class=&quot;headerlink&quot; title=&quot;微服务化-如何拆分数据库&quot;&gt;&lt;/a&gt;微服务化-如何拆分数据库&lt;/h1&gt;&lt;p&gt;在将单体应用拆分为较小服务的过程中，最难的部分就是单体服务数
      
    
    </summary>
    
      <category term="微服务" scheme="https://www.omingo.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="转载" scheme="https://www.omingo.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
      <category term="数据库" scheme="https://www.omingo.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>构建高可用eureka镜像</title>
    <link href="https://www.omingo.com/2020/08/17/%E6%9E%84%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8eureka%E9%95%9C%E5%83%8F/"/>
    <id>https://www.omingo.com/2020/08/17/构建高可用eureka镜像/</id>
    <published>2020-08-17T05:46:19.000Z</published>
    <updated>2020-08-17T07:02:09.046Z</updated>
    
    <content type="html"><![CDATA[<p>服务注册和发现组件是微服务架构中很重要的一个组件，在生产环境中要避免产生单点故障。一定要跑多个互为备份的实例。本文讲述如何构建一个在k8s环境中可自由扩展实例的eureka镜像。</p><h2 id="应用配置"><a href="#应用配置" class="headerlink" title="应用配置"></a>应用配置</h2><p>如何创建<code>spring-cloud</code>eureka项目就不多说了，我只列一下<code>application.yaml</code>中的关键配置。</p><pre><code class="yaml">server:  port: 8761management:  server:    port: 8081  endpoints:    web:      exposure:        include: &#39;*&#39;  endpoint:    health:      show-details: always</code></pre><h2 id="Dockfile"><a href="#Dockfile" class="headerlink" title="Dockfile"></a>Dockfile</h2><p><code>Dockerfile</code>是打包的关键，采用<code>openjdk:8-jre-alpine</code>作为基础镜像。</p><pre><code class="dockerfile">FROM openjdk:8-jre-alpineMAINTAINER wujiming &lt;wzslw@163.com&gt;#  安装curl 和 bashRUN apk add --update \     curl bash \    &amp;&amp; rm -rf /var/cache/apk/*# 解决容器内时区问题ENV TZ=Asia/ShanghaiCOPY target/*.jar app.jarCOPY entrypoint.sh /entrypoint.sh  RUN chmod +x /entrypoint.shRUN echo $(date) &gt; /image_built_atENTRYPOINT [&quot;/entrypoint.sh&quot;]CMD [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;]EXPOSE 8081 8761</code></pre><p>entrypoint.sh</p><pre><code class="bash">#!/usr/bin/env bashset -e#MY_POD_NAME=&quot;mypodname&quot;#MY_IN_SERVICE_NAME=&quot;myinservicename&quot;#MY_POD_NAMESPACE=&quot;mypodnamespace&quot;#EUREKA_REPLICAS=3EUREKA_HOST_NAME=&quot;$MY_POD_NAME.$MY_IN_SERVICE_NAME.$MY_POD_NAMESPACE&quot;export EUREKA_HOST_NAME=$EUREKA_HOST_NAMEBOOL_REGISTER=&quot;true&quot;BOOL_FETCH=&quot;true&quot;EUREKA_REPLICAS=${EUREKA_REPLICAS:-&quot;1&quot;} # 默认副本数为1if [ $EUREKA_REPLICAS = 1 ];then  echo &quot;Eureka副本数为1.&quot;  BOOL_REGISTER=&quot;false&quot;  BOOL_FETCH=&quot;false&quot;  EUREKA_URL_LIST=&quot;http://localhost:8761/eureka/,&quot;  echo &quot;EUREKA_URL_LIST is $EUREKA_URL_LIST&quot;else  echo &quot;Eureka副本数为 $EUREKA_REPLICAS&quot;  BOOL_REGISTER=&quot;true&quot;    BOOL_FETCH=&quot;true&quot;    for ((i=0 ; i&lt;$EUREKA_REPLICAS ; i++))    do      temp=&quot;http://$MY_POD_NAME-$i.$MY_IN_SERVICE_NAME.$MY_POD_NAMESPACE:8761/eureka/,&quot;      EUREKA_URL_LIST=&quot;$EUREKA_URL_LIST$temp&quot;    donefiEUREKA_URL_LIST=${EUREKA_URL_LIST%?}echo &quot;EUREKA_URL_LIST is $EUREKA_URL_LIST&quot;export EUREKA_CLIENT_SERVICEURL_DEFAULTZONE=$EUREKA_URL_LISTexport EUREKA_CLIENT_REGISTERWITHEUREKA=$BOOL_REGISTERexport EUREKA_CLIENT_FETCHREGISTRY=$BOOL_FETCHexec &quot;$@&quot;</code></pre><p>将<code>Dockerfile</code>和<code>entrypoint.sh</code>放到项目根目录下，应用程序打包后，构建docker镜像就可以了。</p><h2 id="服务编排"><a href="#服务编排" class="headerlink" title="服务编排"></a>服务编排</h2><p>上面打包好的镜像需要部署到k8s中,。</p><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  name: eureka-server  labels:    app: eurekaspec:  ports:    - port: 8761      name: eureka  clusterIP: None  selector:    app: eureka---apiVersion: apps/v1kind: StatefulSetmetadata:  name: eurekaspec:  podManagementPolicy: Parallel # 并行启动  replicas: 2 # 副本数  selector:    matchLabels:      app: eureka  serviceName: eureka-server  template:    metadata:      labels:        app: eureka    spec:      containers:      - env:        - name: EUREKA_REPLICAS          value: &quot;2&quot; #跟副本数保持一致        - name: MY_IN_SERVICE_NAME          value: eureka-server #跟上面定义的Headless Service名字保持一致        - name: MY_POD_NAME          valueFrom:            fieldRef:              apiVersion: v1              fieldPath: metadata.name        - name: MY_POD_NAMESPACE          valueFrom:            fieldRef:              apiVersion: v1              fieldPath: metadata.namespace        image: eureka-server # 和你自己的镜像名字保持一致        livenessProbe:          failureThreshold: 3          httpGet:            path: /actuator/health            port: 8081 # 与应用配置中的management.server.port保持一致            scheme: HTTP          initialDelaySeconds: 10          periodSeconds: 2          successThreshold: 1          timeoutSeconds: 2        name: eureka-server        ports:        - containerPort: 8761          name: tcp8761          protocol: TCP        readinessProbe:          failureThreshold: 3          httpGet:            path: /actuator/health            port: 8081 # 与应用配置中的management.server.port保持一致            scheme: HTTP          initialDelaySeconds: 10          periodSeconds: 2          successThreshold: 2          timeoutSeconds: 2        resources:          limits:            memory: 1Gi          requests:            memory: 512Mi</code></pre><p>大功告成。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;服务注册和发现组件是微服务架构中很重要的一个组件，在生产环境中要避免产生单点故障。一定要跑多个互为备份的实例。本文讲述如何构建一个在k8s环境中可自由扩展实例的eureka镜像。&lt;/p&gt;
&lt;h2 id=&quot;应用配置&quot;&gt;&lt;a href=&quot;#应用配置&quot; class=&quot;header
      
    
    </summary>
    
      <category term="微服务" scheme="https://www.omingo.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="服务发现" scheme="https://www.omingo.com/tags/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"/>
    
      <category term="高可用" scheme="https://www.omingo.com/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>keycloak-mybatis整合</title>
    <link href="https://www.omingo.com/2020/06/08/keycloak-mybatis%E6%95%B4%E5%90%88/"/>
    <id>https://www.omingo.com/2020/06/08/keycloak-mybatis整合/</id>
    <published>2020-06-08T06:39:23.000Z</published>
    <updated>2020-06-08T06:44:12.277Z</updated>
    
    <content type="html"><![CDATA[<h1 id="keycloak-整合mybatis"><a href="#keycloak-整合mybatis" class="headerlink" title="keycloak-整合mybatis"></a>keycloak-整合mybatis</h1><p>为方便一些不会jpa的同学，特意整理了一下与mybatis的结合使用方式。</p><p>放码过来。</p><h2 id="依赖-配置"><a href="#依赖-配置" class="headerlink" title="依赖\配置"></a>依赖\配置</h2><p>数据源配置参考： <a href="https://www.omingo.cn/2020/05/11/keycloak-多数据源配置/" target="_blank" rel="noopener">keycloak-多数据源配置</a><br>maven 依赖和打包配置。<br><code>pom.xml</code></p><pre><code class="xml">&lt;!--...--&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.mybatis&lt;/groupId&gt;      &lt;artifactId&gt;mybatis&lt;/artifactId&gt;      &lt;version&gt;3.5.4&lt;/version&gt;    &lt;/dependency&gt;&lt;!--...--&gt; &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;        &lt;version&gt;3.2.3&lt;/version&gt;        &lt;configuration&gt;          &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt;          &lt;webResources&gt;            &lt;resource&gt;              &lt;directory&gt;${project.build.directory}/classes/META-INF/services&lt;/directory&gt;              &lt;targetPath&gt;META-INF/services&lt;/targetPath&gt;              &lt;includes&gt;                &lt;include&gt;*.*&lt;/include&gt;              &lt;/includes&gt;            &lt;/resource&gt;            &lt;resource&gt;              &lt;directory&gt;src/main/java&lt;/directory&gt;              &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt;              &lt;includes&gt;                &lt;include&gt;**/*Mapper.xml&lt;/include&gt;&lt;!--关键点--&gt;              &lt;/includes&gt;              &lt;filtering&gt;true&lt;/filtering&gt;            &lt;/resource&gt;          &lt;/webResources&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;     &lt;!--...--&gt; </code></pre><p><code>resources/META-INF</code>加入<code>mybatisconfig.xml</code>配置文件：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration  PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;  &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;  &lt;environments default=&quot;development&quot;&gt;    &lt;environment id=&quot;development&quot;&gt;      &lt;transactionManager type=&quot;MANAGED&quot;/&gt;      &lt;dataSource type=&quot;JNDI&quot;&gt;        &lt;property name=&quot;data_source&quot; value=&quot;java:jboss/datasources/DapengXADS&quot;/&gt;&lt;!--自定义数据源名称要一致--&gt;      &lt;/dataSource&gt;    &lt;/environment&gt;  &lt;/environments&gt;  &lt;mappers&gt;    &lt;mapper resource=&quot;com/dapeng/cloud/models/mybatis/UserMapper.xml&quot;/&gt;  &lt;/mappers&gt;&lt;/configuration&gt;</code></pre><h2 id="UserStorageProviderFactory"><a href="#UserStorageProviderFactory" class="headerlink" title="UserStorageProviderFactory"></a>UserStorageProviderFactory</h2><pre><code class="java">@JBossLog@AutoService(MybatisStorageProviderFactory.class)public class MybatisStorageProviderFactory implements UserStorageProviderFactory&lt;DapengUserStorageProvider&gt;{  private static final String PROVIDER_NAME=&quot;dapeng-jdbc&quot;;  private static final String MYBATIS_CONFIG=&quot;META-INF/mybatis-config.xml&quot;;  private SqlSessionFactory sqlSessionFactory;  @Override  public void init(Scope config) {    try {      InputStream in = Resources.getResourceAsStream(MYBATIS_CONFIG);      sqlSessionFactory=new SqlSessionFactoryBuilder().build(in);    } catch (IOException e) {      log.error(&quot;创建sqlSessionFactory失败&quot;,e);      e.printStackTrace();    }  }  public String getId() {    return PROVIDER_NAME;  }  public MybatisUserStorageProvider create(KeycloakSession keycloakSession, ComponentModel componentModel) {      return new MybatisUserStorageProvider(keycloakSession,componentModel,sqlSessionFactory.openSession());  }}</code></pre><h2 id="MybatisUserStorageProvider"><a href="#MybatisUserStorageProvider" class="headerlink" title="MybatisUserStorageProvider"></a>MybatisUserStorageProvider</h2><pre><code class="java">@JBossLog@Data@AllArgsConstructorpublic class MybatisUserStorageProvider implements UserStorageProvider, UserLookupProvider,  CredentialInputValidator {  private  KeycloakSession session;  private  ComponentModel componentModel;  private SqlSession sqlSession;  @Override  public UserModel getUserById(String id,    RealmModel realmModel) {    User user = (User)sqlSession.selectOne(&quot;com.dapeng.cloud.models.mybatis.UserMapper.findById&quot;, id);    log.debugv(&quot;用户:{0}&quot;,user);    return new UserAdapter(session,realmModel,componentModel,user);  }  @Override  public UserModel getUserByUsername(String username, RealmModel realmModel) {    log.debugv(&quot;获取用户信息 用户名:{0},域:{1}&quot;,username,realmModel.getName());    User user =(User)sqlSession.selectOne(&quot;com.dapeng.cloud.models.mybatis.UserMapper.findByMobile&quot;, username);    return new UserAdapter(session,realmModel, componentModel,user);  }  @Override  public UserModel getUserByEmail(String s, RealmModel realmModel) {    return null;  }  @Override  public boolean supportsCredentialType(String credentialType) {    return PasswordCredentialModel.TYPE.equals(credentialType);  }  @Override  public boolean isConfiguredFor(RealmModel realm, UserModel user, String credentialType) {    return PasswordCredentialModel.TYPE.equals(credentialType)&amp;&amp;user instanceof UserAdapter;  }  @Override  public boolean isValid(RealmModel realm, UserModel user,    CredentialInput credentialInput) {    if (!supportsCredentialType(credentialInput.getType())) return false;    String in = credentialInput.getChallengeResponse();    log.infof(&quot;input password: %s ,&quot;, in);    return &quot;123456&quot;.equals(in);  }  @Override  public void close() {  }}</code></pre><p>剩下的就是mybatis的常规操作了，这里不在赘述。</p><p>有问题请留言。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;keycloak-整合mybatis&quot;&gt;&lt;a href=&quot;#keycloak-整合mybatis&quot; class=&quot;headerlink&quot; title=&quot;keycloak-整合mybatis&quot;&gt;&lt;/a&gt;keycloak-整合mybatis&lt;/h1&gt;&lt;p&gt;为方便一些不
      
    
    </summary>
    
      <category term="Keycloak" scheme="https://www.omingo.com/categories/Keycloak/"/>
    
    
      <category term="keycloak" scheme="https://www.omingo.com/tags/keycloak/"/>
    
  </entry>
  
  <entry>
    <title>keycloak-用户session数量限制</title>
    <link href="https://www.omingo.com/2020/06/08/keycloak-%E7%94%A8%E6%88%B7session%E6%95%B0%E9%87%8F%E9%99%90%E5%88%B6/"/>
    <id>https://www.omingo.com/2020/06/08/keycloak-用户session数量限制/</id>
    <published>2020-06-08T05:40:52.000Z</published>
    <updated>2020-06-08T05:46:24.887Z</updated>
    
    <content type="html"><![CDATA[<h1 id="session并发限制"><a href="#session并发限制" class="headerlink" title="session并发限制"></a>session并发限制</h1><p>有时候需要限制用户同时在线的数量，就像微信一样同一时间只能有一个手机能够登陆上。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>废话不多说，直接放码,要的拿去。</p><p><code>UserSessionLimitsAuthenticatorFactory.java</code></p><pre><code class="java">@AutoService(AuthenticatorFactory.class)public class UserSessionLimitsAuthenticatorFactory implements AuthenticatorFactory {  public static final String USER_REALM_LIMIT = &quot;userRealmLimit&quot;;  public static final String USER_CLIENT_LIMIT = &quot;userClientLimit&quot;;  public static final String BEHAVIOR = &quot;behavior&quot;;  public static final String DENY_NEW_SESSION = &quot;Deny new session&quot;;  public static final String TERMINATE_OLDEST_SESSION = &quot;Terminate oldest session&quot;;  public static final String USER_SESSION_LIMITS = &quot;user-session-limits&quot;;  private static final AuthenticationExecutionModel.Requirement[] REQUIREMENT_CHOICES = {    AuthenticationExecutionModel.Requirement.REQUIRED,    AuthenticationExecutionModel.Requirement.DISABLED  };  @Override  public String getDisplayType() {    return &quot;User session count limiter&quot;;  }  @Override  public String getReferenceCategory() {    return null;  }  @Override  public boolean isConfigurable() {    return true;  }  @Override  public AuthenticationExecutionModel.Requirement[] getRequirementChoices() {    return REQUIREMENT_CHOICES.clone();  }  @Override  public boolean isUserSetupAllowed() {    return false;  }  @Override  public String getHelpText() {    return &quot;Configures how many concurrent sessions a single user is allowed to create for this realm and/or client&quot;;  }  @Override  public List&lt;ProviderConfigProperty&gt; getConfigProperties() {    ProviderConfigProperty userRealmLimit = new ProviderConfigProperty();    userRealmLimit.setName(USER_REALM_LIMIT);    userRealmLimit.setLabel(&quot;Maximum concurrent sessions for each user&quot;);    userRealmLimit.setType(ProviderConfigProperty.STRING_TYPE);    ProviderConfigProperty userClientLimit = new ProviderConfigProperty();    userClientLimit.setName(USER_CLIENT_LIMIT);    userClientLimit.setLabel(&quot;Maximum concurrent sessions for each user per keycloak client&quot;);    userClientLimit.setType(ProviderConfigProperty.STRING_TYPE);    ProviderConfigProperty behaviourProperty = new ProviderConfigProperty();    behaviourProperty.setName(BEHAVIOR);    behaviourProperty.setLabel(&quot;Behavior when user session limit is exceeded&quot;);    behaviourProperty.setType(ProviderConfigProperty.LIST_TYPE);    behaviourProperty.setDefaultValue(DENY_NEW_SESSION);    behaviourProperty.setOptions(Arrays.asList(DENY_NEW_SESSION, TERMINATE_OLDEST_SESSION));    return Arrays.asList(userRealmLimit, userClientLimit, behaviourProperty);  }  @Override  public Authenticator create(KeycloakSession keycloakSession) {    return new UserSessionLimitsAuthenticator(keycloakSession);  }  @Override  public void init(Config.Scope scope) {    // Do nothing  }  @Override  public void postInit(KeycloakSessionFactory keycloakSessionFactory) {    // Do nothing  }  @Override  public void close() {    // Do nothing  }  @Override  public String getId() {    return USER_SESSION_LIMITS;  }}</code></pre><p><code>AbstractSessionLimitsAuthenticator.java</code></p><pre><code class="java">public abstract class AbstractSessionLimitsAuthenticator implements Authenticator {  protected KeycloakSession session;  protected boolean exceedsLimit(long count, long limit) {    if (limit &lt; 0) { // if limit is negative, no valid limit configuration is found      return false;    }    return count &gt; limit - 1;  }  protected int getIntConfigProperty(String key, Map&lt;String, String&gt; config) {    String value = config.get(key);    if (StringUtils.isBlank(value)) {      return -1;    }    return Integer.parseInt(value);  }  @Override  public void action(AuthenticationFlowContext context) {  }  @Override  public boolean requiresUser() {    return false;  }  @Override  public boolean configuredFor(KeycloakSession session, RealmModel realm, UserModel user) {    return true;  }  @Override  public void setRequiredActions(KeycloakSession session, RealmModel realm, UserModel user) {  }  @Override  public void close() {  }}</code></pre><p><code>UserSessionLimitsAuthenticator.java</code></p><pre><code class="java">@JBossLogpublic class UserSessionLimitsAuthenticator extends AbstractSessionLimitsAuthenticator {  String behavior;  public UserSessionLimitsAuthenticator(KeycloakSession session) {    this.session = session;  }  @Override  public void authenticate(AuthenticationFlowContext context) {    AuthenticatorConfigModel authenticatorConfig = context.getAuthenticatorConfig();    Map&lt;String, String&gt; config = authenticatorConfig.getConfig();    // Get the configuration for this authenticator    behavior = config.get(UserSessionLimitsAuthenticatorFactory.BEHAVIOR);    int userRealmLimit = getIntConfigProperty(      UserSessionLimitsAuthenticatorFactory.USER_REALM_LIMIT, config);    int userClientLimit = getIntConfigProperty(      UserSessionLimitsAuthenticatorFactory.USER_CLIENT_LIMIT, config);    if (context.getRealm() != null &amp;&amp; context.getUser() != null) {      // Get the session count in this realm for this specific user      List&lt;UserSessionModel&gt; userSessionsForRealm = session.sessions()        .getUserSessions(context.getRealm(), context.getUser());      int userSessionCountForRealm = userSessionsForRealm.size();      // Get the session count related to the current client for this user      ClientModel currentClient = context.getAuthenticationSession().getClient();      log.infof(&quot;session-limiter&#39;s current keycloak clientId: %s&quot;, currentClient.getClientId());      List&lt;UserSessionModel&gt; userSessionsForClient = userSessionsForRealm.stream().filter(        session -&gt; session.getAuthenticatedClientSessionByClient(currentClient.getId()) != null)        .collect(Collectors.toList());      int userSessionCountForClient = userSessionsForClient.size();      log.infof(&quot;session-limiter&#39;s configured realm session limit: %s&quot;, userRealmLimit);      log.infof(&quot;session-limiter&#39;s configured client session limit: %s&quot;, userClientLimit);      log.infof(        &quot;session-limiter&#39;s count of total user sessions for the entire realm (could be apps other than web apps): %s&quot;,        userSessionCountForRealm);      log.infof(&quot;session-limiter&#39;s count of total user sessions for this keycloak client: %s&quot;,        userSessionCountForClient);      // First check if the user has too many sessions in this realm      if (exceedsLimit(userSessionCountForRealm, userRealmLimit)) {        log.info(&quot;Too many session in this realm for the current user.&quot;);        handleLimitExceeded(context, userSessionsForRealm);      } // otherwise if the user is still allowed to create a new session in the realm, check if this applies for this specific client as well.      else if (exceedsLimit(userSessionCountForClient, userClientLimit)) {        log.info(&quot;Too many sessions related to the current client for this user.&quot;);        handleLimitExceeded(context, userSessionsForClient);      } else {        context.success();      }    } else {      context.success();    }  }  private void handleLimitExceeded(AuthenticationFlowContext context,    List&lt;UserSessionModel&gt; userSessions) {    switch (behavior) {      case UserSessionLimitsAuthenticatorFactory.DENY_NEW_SESSION:        log.info(&quot;Denying new session&quot;);        context.failure(AuthenticationFlowError.INVALID_CLIENT_SESSION);        break;      case UserSessionLimitsAuthenticatorFactory.TERMINATE_OLDEST_SESSION:        log.info(&quot;Terminating oldest session&quot;);        logoutOldestSession(userSessions);        context.success();        break;      default:        break;    }  }  private void logoutOldestSession(List&lt;UserSessionModel&gt; userSessions) {    log.info(&quot;Logging out oldest session&quot;);    Optional&lt;UserSessionModel&gt; oldest = userSessions.stream()      .sorted(Comparator.comparingInt(UserSessionModel::getStarted)).findFirst();    oldest.ifPresent(      userSession -&gt; AuthenticationManager.backchannelLogout(session, userSession, true));  }}</code></pre><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>authentication flow<br><img src="20200608132937418_908857975.png" alt><br>点<code>config</code> 进行配置。<br><img src="20200608133708658_234115439.png" alt><br>可设置 每个用户可以最多有几个session。对每个client最多可以有几个session。 如果session数量超过限制如何处理：有两种选择，一、 拒绝创建新session。二、结束老session。</p><p>已测可用。 有问题请留言。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;session并发限制&quot;&gt;&lt;a href=&quot;#session并发限制&quot; class=&quot;headerlink&quot; title=&quot;session并发限制&quot;&gt;&lt;/a&gt;session并发限制&lt;/h1&gt;&lt;p&gt;有时候需要限制用户同时在线的数量，就像微信一样同一时间只能有一个手机
      
    
    </summary>
    
      <category term="Keycloak" scheme="https://www.omingo.com/categories/Keycloak/"/>
    
    
      <category term="keycloak" scheme="https://www.omingo.com/tags/keycloak/"/>
    
  </entry>
  
  <entry>
    <title>keycloak-多数据源配置</title>
    <link href="https://www.omingo.com/2020/05/11/keycloak-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.omingo.com/2020/05/11/keycloak-多数据源配置/</id>
    <published>2020-05-11T09:08:40.000Z</published>
    <updated>2020-06-09T03:22:25.784Z</updated>
    
    <content type="html"><![CDATA[<h1 id="keycloak-连接自己的数据库"><a href="#keycloak-连接自己的数据库" class="headerlink" title="keycloak-连接自己的数据库"></a>keycloak-连接自己的数据库</h1><p>当开发UserStorage SPI时,我们可能需要访问一个非keycloak数据库来读取用户数据.<br>本文演示如何给keycloak加一个数据库源.</p><h2 id="修改keycloak数据库为XA数据源"><a href="#修改keycloak数据库为XA数据源" class="headerlink" title="修改keycloak数据库为XA数据源"></a>修改keycloak数据库为XA数据源</h2><p>关于java分布式事务请参考<a href="https://blog.csdn.net/zhouhao88410234/article/details/91872872?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-8&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-8" target="_blank" rel="noopener">JTA和XA</a></p><p>在standalone.xml搜索 urn:jboss:domain:datasources,在datasources标签下增加:</p><pre><code class="xml">                &lt;xa-datasource jndi-name=&quot;java:jboss/datasources/KeycloakXADS&quot; pool-name=&quot;KeycloakXADS&quot;&gt;                    &lt;xa-datasource-property name=&quot;url&quot;&gt;                        jdbc:mysql://localhost:3306/keycloak?useSSL=false                    &lt;/xa-datasource-property&gt;                    &lt;driver&gt;mysql&lt;/driver&gt;                    &lt;security&gt;                        &lt;user-name&gt;root&lt;/user-name&gt;                        &lt;password&gt;root&lt;/password&gt;                    &lt;/security&gt;                    &lt;validation&gt;                        &lt;valid-connection-checker class-name=&quot;org.jboss.jca.adapters.jdbc.extensions.mysql.MySQLValidConnectionChecker&quot;/&gt;                        &lt;exception-sorter class-name=&quot;org.jboss.jca.adapters.jdbc.extensions.mysql.MySQLExceptionSorter&quot;/&gt;                    &lt;/validation&gt;                &lt;/xa-datasource&gt;</code></pre><p>搜索<code>&lt;spi name=&quot;connectionsJpa&quot;&gt;</code> ,然后修改为:</p><pre><code class="xml">            &lt;spi name=&quot;connectionsJpa&quot;&gt;                &lt;provider name=&quot;default&quot; enabled=&quot;true&quot;&gt;                    &lt;properties&gt;                        &lt;property name=&quot;dataSource&quot; value=&quot;java:jboss/datasources/KeycloakXADS&quot;/&gt;&lt;!--修改为XA数据源--&gt;                        &lt;property name=&quot;showSql&quot; value=&quot;true&quot;/&gt;                        &lt;property name=&quot;initializeEmpty&quot; value=&quot;true&quot;/&gt;                        &lt;property name=&quot;migrationStrategy&quot; value=&quot;update&quot;/&gt;                        &lt;property name=&quot;migrationExport&quot; value=&quot;${jboss.home.dir}/keycloak-database-update.sql&quot;/&gt;                    &lt;/properties&gt;                &lt;/provider&gt;</code></pre><h2 id="增加自己的XA数据源"><a href="#增加自己的XA数据源" class="headerlink" title="增加自己的XA数据源"></a>增加自己的XA数据源</h2><p>在standalone.xml搜索 urn:jboss:domain:datasources,在datasources标签下增加:</p><pre><code class="xml">                &lt;xa-datasource jndi-name=&quot;java:jboss/datasources/DapengXADS&quot; pool-name=&quot;DapengXADS&quot;&gt;                    &lt;xa-datasource-property name=&quot;url&quot;&gt;                        jdbc:mysql://192.168.1.254:3306/dapeng_app?useSSL=false                    &lt;/xa-datasource-property&gt;                    &lt;driver&gt;mysql&lt;/driver&gt;                    &lt;security&gt;                        &lt;user-name&gt;root&lt;/user-name&gt;                        &lt;password&gt;root&lt;/password&gt;                    &lt;/security&gt;                    &lt;validation&gt;                        &lt;valid-connection-checker class-name=&quot;org.jboss.jca.adapters.jdbc.extensions.mysql.MySQLValidConnectionChecker&quot;/&gt;                        &lt;background-validation&gt;true&lt;/background-validation&gt;                        &lt;exception-sorter class-name=&quot;org.jboss.jca.adapters.jdbc.extensions.mysql.MySQLExceptionSorter&quot;/&gt;                    &lt;/validation&gt;                &lt;/xa-datasource&gt;</code></pre><h2 id="在自己的SPI-Extension中使用新数据源"><a href="#在自己的SPI-Extension中使用新数据源" class="headerlink" title="在自己的SPI Extension中使用新数据源"></a>在自己的SPI Extension中使用新数据源</h2><p>如何编写 SPI Extension 请参考官方文档 <a href="https://www.keycloak.org/docs/latest/server_development/#_providers" target="_blank" rel="noopener">Service Provider Interfaces (SPI)</a><br>首先在 <code>resources/META-INF/</code>创建<code>persistence.xml</code>:</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;persistence xmlns=&quot;http://java.sun.com/xml/ns/persistence&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_1_0.xsd&quot; version=&quot;1.0&quot;&gt;  &lt;persistence-unit name=&quot;keycloak-dapeng&quot; transaction-type=&quot;RESOURCE_LOCAL&quot; &gt;    &lt;description&gt;Dapeng Persistence Unit&lt;/description&gt;    &lt;jta-data-source&gt;java:jboss/datasources/DapengXADS&lt;/jta-data-source&gt;    &lt;class&gt;com.dapeng.cloud.models.jpa.User&lt;/class&gt;    &lt;properties&gt;      &lt;property name=&quot;jboss.entity.manager.factory.jndi.name&quot; value=&quot;java:jboss/emf/Dapeng&quot;/&gt;&lt;!--暴露为wildfly全局jndi--&gt;      &lt;property name=&quot;hibernate.connection.provider_disables_autocommit&quot; value=&quot;true&quot;/&gt;&lt;!--注意这里设置,否则出现无法更新数据库错误--&gt;      &lt;property name=&quot;hibernate.hbm2ddl.auto&quot; value=&quot;none&quot;/&gt;&lt;!--注意这里设置,否则容易删库!!!--&gt;      &lt;property name=&quot;hibernate.show_sql&quot; value=&quot;true&quot; /&gt;    &lt;/properties&gt;  &lt;/persistence-unit&gt;&lt;/persistence&gt;</code></pre><blockquote><p> hibernate.connection.provider_disables_autocommit 不配置为true的话，在进行更新操作的时候会报：<code>you cannot set autocommit during a managed transaction</code> 异常。</p></blockquote><p>参考资料: <a href="https://docs.jboss.org/ejb3/app-server/reference/build/reference/en/html/entityconfig.html#referencing" target="_blank" rel="noopener">暴露emf全局jndi</a></p><p>编写一个工具类用来获取<code>EntityManagerFactory</code>:</p><pre><code class="java">public class JndiEntityManagerLookup {  public static EntityManager getEntityManager(String entityManagerFactoryJndiName) {    EntityManagerFactory factory = null;    try {      factory = (EntityManagerFactory)(new InitialContext()).lookup(entityManagerFactoryJndiName);    } catch (NamingException var4) {      throw new RuntimeException(var4);    }    return factory.createEntityManager();  }}</code></pre><p>然后在你的<code>ProviderFactory.create</code>中就可以愉快的使用新加的数据源了,剩下的请自由发挥:</p><pre><code class="java">  public DapengUserStorageProvider create(KeycloakSession keycloakSession, ComponentModel componentModel) {    EntityManager em=JndiEntityManagerLookup.getEntityManager(EMC_JNDI);      return new DapengUserStorageProvider(keycloakSession,componentModel,em);  }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;keycloak-连接自己的数据库&quot;&gt;&lt;a href=&quot;#keycloak-连接自己的数据库&quot; class=&quot;headerlink&quot; title=&quot;keycloak-连接自己的数据库&quot;&gt;&lt;/a&gt;keycloak-连接自己的数据库&lt;/h1&gt;&lt;p&gt;当开发UserSto
      
    
    </summary>
    
      <category term="Keycloak" scheme="https://www.omingo.com/categories/Keycloak/"/>
    
    
      <category term="keycloak" scheme="https://www.omingo.com/tags/keycloak/"/>
    
  </entry>
  
  <entry>
    <title>数据源配置</title>
    <link href="https://www.omingo.com/2020/05/11/%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.omingo.com/2020/05/11/数据源配置/</id>
    <published>2020-05-11T05:01:42.000Z</published>
    <updated>2020-05-11T05:14:49.476Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据源配置"><a href="#数据源配置" class="headerlink" title="数据源配置"></a>数据源配置</h1><p>Keycloak默认使用的数据库是H2。H2数据库在高并发情况下不太可行，也不应该在集群中使用。因此我们应该把Keycloak连接到更成熟的数据库。<br>本文以mysql5为例子.</p><h2 id="安装jdbc驱动"><a href="#安装jdbc驱动" class="headerlink" title="安装jdbc驱动."></a>安装jdbc驱动.</h2><p><img src="20200509104802818_1785251963.png" alt><br>module.xml 内容:</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot;?&gt;&lt;module xmlns=&quot;urn:jboss:module:1.3&quot; name=&quot;com.mysql&quot;&gt;    &lt;resources&gt;        &lt;resource-root path=&quot;mysql-connector-java-5.1.48.jar&quot;/&gt;    &lt;/resources&gt;    &lt;dependencies&gt;        &lt;module name=&quot;javax.api&quot;/&gt;        &lt;module name=&quot;javax.transaction.api&quot;/&gt;    &lt;/dependencies&gt;&lt;/module&gt;</code></pre><p> <a href="https://www.keycloak.org/docs/latest/server_installation/#_database" target="_blank" rel="noopener">参考官方文档</a></p><h2 id="声明并加载驱动"><a href="#声明并加载驱动" class="headerlink" title="声明并加载驱动"></a>声明并加载驱动</h2><p>在<code>standalone.xml</code>搜索  <em>urn:jboss:domain:datasources</em>,然后修改:</p><pre><code class="xml">       &lt;subsystem xmlns=&quot;urn:jboss:domain:datasources:5.0&quot;&gt;           &lt;!--.....--&gt;                &lt;drivers&gt;                    &lt;driver name=&quot;h2&quot; module=&quot;com.h2database.h2&quot;&gt;                        &lt;xa-datasource-class&gt;org.h2.jdbcx.JdbcDataSource&lt;/xa-datasource-class&gt;                    &lt;/driver&gt;                    &lt;driver name=&quot;mysql&quot; module=&quot;com.mysql&quot;&gt; &lt;!--增加mysql驱动声明--&gt;                        &lt;xa-datasource-class&gt;com.mysql.jdbc.jdbc2.optional.MysqlXADataSource&lt;/xa-datasource-class&gt;                    &lt;/driver&gt;                &lt;/drivers&gt;            &lt;/datasources&gt;        &lt;/subsystem&gt;</code></pre><h2 id="修改keycloak数据源"><a href="#修改keycloak数据源" class="headerlink" title="修改keycloak数据源"></a>修改keycloak数据源</h2><p>在<code>standalone.xml</code>搜索  <em>urn:jboss:domain:datasources</em>,然后修改:</p><pre><code class="xml">        &lt;subsystem xmlns=&quot;urn:jboss:domain:datasources:5.0&quot;&gt;            &lt;datasources&gt;                &lt;datasource jndi-name=&quot;java:jboss/datasources/ExampleDS&quot; pool-name=&quot;ExampleDS&quot; enabled=&quot;true&quot; use-java-context=&quot;true&quot; statistics-enabled=&quot;${wildfly.datasources.statistics-enabled:${wildfly.statistics-enabled:false}}&quot;&gt;                    &lt;connection-url&gt;jdbc:h2:mem:test;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE&lt;/connection-url&gt;                    &lt;driver&gt;h2&lt;/driver&gt;                    &lt;security&gt;                        &lt;user-name&gt;sa&lt;/user-name&gt;                        &lt;password&gt;sa&lt;/password&gt;                    &lt;/security&gt;                &lt;/datasource&gt;                &lt;!-- &lt;datasource jndi-name=&quot;java:jboss/datasources/KeycloakDS&quot; pool-name=&quot;KeycloakDS&quot; enabled=&quot;true&quot; use-java-context=&quot;true&quot; statistics-enabled=&quot;${wildfly.datasources.statistics-enabled:${wildfly.statistics-enabled:false}}&quot;&gt;                    &lt;connection-url&gt;jdbc:h2:${jboss.server.data.dir}/keycloak;AUTO_SERVER=TRUE&lt;/connection-url&gt;                    &lt;driver&gt;h2&lt;/driver&gt;                    &lt;security&gt;                        &lt;user-name&gt;sa&lt;/user-name&gt;                        &lt;password&gt;sa&lt;/password&gt;                    &lt;/security&gt;                &lt;/datasource&gt; --&gt;&lt;!--注释掉keycloak原来的数据源配置,修改为以下配置--&gt;                 &lt;datasource jndi-name=&quot;java:jboss/datasources/KeycloakDS&quot; pool-name=&quot;KeycloakDS&quot; enabled=&quot;true&quot; use-java-context=&quot;true&quot; statistics-enabled=&quot;${wildfly.datasources.statistics-enabled:${wildfly.statistics-enabled:false}}&quot;&gt;                    &lt;connection-url&gt;jdbc:mysql://localhost:3306/keycloak?useSSL=false&lt;/connection-url&gt;                    &lt;driver&gt;mysql&lt;/driver&gt;                    &lt;security&gt;                        &lt;user-name&gt;root&lt;/user-name&gt;                        &lt;password&gt;root&lt;/password&gt;                    &lt;/security&gt;                    &lt;validation&gt;                        &lt;valid-connection-checker class-name=&quot;org.jboss.jca.adapters.jdbc.extensions.mysql.MySQLValidConnectionChecker&quot;/&gt;                        &lt;background-validation&gt;true&lt;/background-validation&gt;                        &lt;exception-sorter class-name=&quot;org.jboss.jca.adapters.jdbc.extensions.mysql.MySQLExceptionSorter&quot;/&gt;                    &lt;/validation&gt;                &lt;/datasource&gt;                               &lt;!--.....--&gt;            &lt;/datasources&gt;        &lt;/subsystem&gt;</code></pre><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p>在mysql创建 <code>keycloak</code>数据库,字符编码为为<code>utf-8</code>.<br>然后运行keycloak.<br>效果:<br><img src="20200509111740568_962106095.png" alt="Untitled"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据源配置&quot;&gt;&lt;a href=&quot;#数据源配置&quot; class=&quot;headerlink&quot; title=&quot;数据源配置&quot;&gt;&lt;/a&gt;数据源配置&lt;/h1&gt;&lt;p&gt;Keycloak默认使用的数据库是H2。H2数据库在高并发情况下不太可行，也不应该在集群中使用。因此我们应该把Key
      
    
    </summary>
    
      <category term="Keycloak" scheme="https://www.omingo.com/categories/Keycloak/"/>
    
    
      <category term="keycloak" scheme="https://www.omingo.com/tags/keycloak/"/>
    
  </entry>
  
  <entry>
    <title>keycloak-调整日志打印级别</title>
    <link href="https://www.omingo.com/2020/05/09/keycloak-%E8%B0%83%E6%95%B4%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E7%BA%A7%E5%88%AB/"/>
    <id>https://www.omingo.com/2020/05/09/keycloak-调整日志打印级别/</id>
    <published>2020-05-09T10:33:37.000Z</published>
    <updated>2020-05-09T10:37:41.960Z</updated>
    
    <content type="html"><![CDATA[<h1 id="keycloak-调整日志打印级别"><a href="#keycloak-调整日志打印级别" class="headerlink" title="keycloak-调整日志打印级别"></a>keycloak-调整日志打印级别</h1><p>在开发环境中我们需要调整一下keycloak的日志打印级别,以便我们更方便的了解系统内部执行的情况.</p><p>在<code>standalon.xml</code>搜索<em>urn:jboss:domain:logging</em>,然后修改为:</p><pre><code class="xml">        &lt;subsystem xmlns=&quot;urn:jboss:domain:logging:8.0&quot;&gt;            &lt;console-handler name=&quot;CONSOLE&quot;&gt;                &lt;level name=&quot;DEBUG&quot;/&gt; &lt;!--修改控制台打印级别问题DEBUG--&gt;                &lt;formatter&gt;                    &lt;named-formatter name=&quot;COLOR-PATTERN&quot;/&gt;                &lt;/formatter&gt;            &lt;/console-handler&gt;            &lt;periodic-rotating-file-handler name=&quot;FILE&quot; autoflush=&quot;true&quot;&gt;                &lt;formatter&gt;                    &lt;named-formatter name=&quot;PATTERN&quot;/&gt;                &lt;/formatter&gt;                &lt;file relative-to=&quot;jboss.server.log.dir&quot; path=&quot;server.log&quot;/&gt;                &lt;suffix value=&quot;.yyyy-MM-dd&quot;/&gt;                &lt;append value=&quot;true&quot;/&gt;            &lt;/periodic-rotating-file-handler&gt;            &lt;logger category=&quot;com.arjuna&quot;&gt;                &lt;level name=&quot;WARN&quot;/&gt;            &lt;/logger&gt;            &lt;logger category=&quot;io.jaegertracing.Configuration&quot;&gt;                &lt;level name=&quot;WARN&quot;/&gt;            &lt;/logger&gt;            &lt;logger category=&quot;org.jboss.as.config&quot;&gt;                &lt;level name=&quot;DEBUG&quot;/&gt;            &lt;/logger&gt;            &lt;logger category=&quot;sun.rmi&quot;&gt;                &lt;level name=&quot;WARN&quot;/&gt;            &lt;/logger&gt;            &lt;logger category=&quot;org.keycloak&quot;&gt; &lt;!--增加keycloak logger--&gt;                &lt;level name=&quot;DEBUG&quot;/&gt;            &lt;/logger&gt;                        &lt;root-logger&gt;                &lt;level name=&quot;INFO&quot;/&gt;                &lt;handlers&gt;                    &lt;handler name=&quot;CONSOLE&quot;/&gt;                    &lt;handler name=&quot;FILE&quot;/&gt;                &lt;/handlers&gt;            &lt;/root-logger&gt;            &lt;formatter name=&quot;PATTERN&quot;&gt;                &lt;pattern-formatter pattern=&quot;%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c] (%t) %s%e%n&quot;/&gt;            &lt;/formatter&gt;            &lt;formatter name=&quot;COLOR-PATTERN&quot;&gt;                &lt;pattern-formatter pattern=&quot;%K{level}%d{HH:mm:ss,SSS} %-5p [%c] (%t) %s%e%n&quot;/&gt;            &lt;/formatter&gt;        &lt;/subsystem&gt;</code></pre><p>结果:<br><img src="20200509104304377_598798424.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;keycloak-调整日志打印级别&quot;&gt;&lt;a href=&quot;#keycloak-调整日志打印级别&quot; class=&quot;headerlink&quot; title=&quot;keycloak-调整日志打印级别&quot;&gt;&lt;/a&gt;keycloak-调整日志打印级别&lt;/h1&gt;&lt;p&gt;在开发环境中我们需要
      
    
    </summary>
    
      <category term="Keycloak" scheme="https://www.omingo.com/categories/Keycloak/"/>
    
    
      <category term="keycloak" scheme="https://www.omingo.com/tags/keycloak/"/>
    
      <category term="日志" scheme="https://www.omingo.com/tags/%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>keycloak源码分析-启动</title>
    <link href="https://www.omingo.com/2020/05/09/keycloak%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%90%AF%E5%8A%A8/"/>
    <id>https://www.omingo.com/2020/05/09/keycloak源码分析-启动/</id>
    <published>2020-05-09T10:12:34.000Z</published>
    <updated>2020-05-09T10:23:18.232Z</updated>
    
    <content type="html"><![CDATA[<p>分析版本: 10.0.0</p><h2 id="web-xml"><a href="#web-xml" class="headerlink" title="web.xml"></a>web.xml</h2><p><img src="20200508112409320_335053284.png" alt></p><ol><li><p><code>module-name</code>为<em>auth</em>,这就是为什么启动keyloak服务后要通过 <a href="http://domain/auth进行访问应用的原因了" target="_blank" rel="noopener">http://domain/auth进行访问应用的原因了</a>.</p></li><li><p>我们发现有一个<code>load-on-startup</code>的servlet声明,这个是restEasy的启动声明,详细请参考<a href="https://docs.jboss.org/resteasy/docs/4.5.3.Final/userguide/html/Installation_Configuration.html#d4e143" target="_blank" rel="noopener">Older servlet containers</a>.</p></li></ol><h2 id="WildflyLifecleListener"><a href="#WildflyLifecleListener" class="headerlink" title="WildflyLifecleListener"></a>WildflyLifecleListener</h2><p>里面有个<code>listener</code>声明,实际上启动阶段这个listener什么都没做,到时容器关闭的时候,执行了一个shutdownHook.</p><p><img src="20200508115559301_1073305909.png" alt></p><h2 id="KeycloakApplication"><a href="#KeycloakApplication" class="headerlink" title="KeycloakApplication"></a>KeycloakApplication</h2><p>这个是keycloak启动的入口.</p><div id="flowchart-0" class="flow-chart"></div><p>这里的启动hook主要是做一些系统升级相关的逻辑.关联的shutdownhook主要是把之前创建的sessionFactory关掉. 这个shutdownhook实在上一节中提到的<code>WildflyLifecleListener</code>中调用的</p><p>启动过程中不管出现任何异常,keycloak都会直接exit.</p><h2 id="KeycloakSessionServletFilter"><a href="#KeycloakSessionServletFilter" class="headerlink" title="KeycloakSessionServletFilter"></a>KeycloakSessionServletFilter</h2><p>目光再次回到<code>web.xml</code>上来,这里还有一个<code>KeycloakSessionServletFilter</code>,看一下里面的<code>doFilter</code>都做了什么:</p><p><img src="20200508132807887_775282546.png" alt>SessionFactory和</p><div id="flowchart-1" class="flow-chart"></div><p>这个filter负责创建session,并且打开事务,当出现异常的时候自动回滚事务.当没又出现异常的时候这个事务是如何提交的呢,继续往下分析.</p><h2 id="KeycloakTransactionCommitter"><a href="#KeycloakTransactionCommitter" class="headerlink" title="KeycloakTransactionCommitter"></a>KeycloakTransactionCommitter</h2><p>在上面的KeycloakApplication的代码分析中有这么一句<code>classes.add(KeycloakTransactionCommitter.class);</code>看名字应该是做事务提交用的.</p><p><img src="20200508135716767_851192680.png" alt></p><p>果真如此,但是它只负责在response阶段提交事务,如果提交事务出现异常的时候会直接将异常抛出,然后由<code>KeycloakSessionServletFilter</code>捕获后做回滚.</p><h2 id="RestEasyContext"><a href="#RestEasyContext" class="headerlink" title="RestEasyContext"></a>RestEasyContext</h2><p>目前已经大该分析完了keycloak的启动过程,启动完成后restEasyContext中被push了下面这些对象,这些对象是可以直接通过注解进行注入的.</p><table><thead><tr><th>序号</th><th>类型</th><th>作用域</th><th>描述</th></tr></thead><tbody><tr><td>1</td><td>KeycloakApplication</td><td>gloable</td><td></td></tr><tr><td>2</td><td>KeycloakApplication</td><td>thread</td><td>for injection</td></tr><tr><td>3</td><td>KeycloakSession</td><td>thread</td><td></td></tr><tr><td>4</td><td>ClientConnection</td><td>thread</td><td></td></tr><tr><td>5</td><td>KeycloakTransaction</td><td>thread</td><td></td><td><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">loadConfig=>operation: 加载配置createSessionFectory=>operation: 创建createSessionFactory并将实例加入servletContextresteasyContextPush=>operation: 当前keycloakApplication实例加入resteasyContextaddResource=>operation: 添加resource,filter,事务管理,异常处理和资源解析器addHook=>operation: 执行启动hook,关联shutdownhookloadConfig->createSessionFectory->resteasyContextPush->addResource->addHook->loadConfig</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><textarea id="flowchart-1-code" style="display: none">encoding=>operation: 设置请求编码为UTF-8getSessionFactory=>operation: 从servletRequestContext中取出sessionFactorycreateSession=>operation: 创建keycloakSession并push到ResteasyContextconnection=>operation: 由request创建了一个ClientConnection对象并关联到sessionContext和push到resteasyContexttx=>operation: 从session获取事务管理器实例并push进resteasyContext,然后打开事务doFilter=>operation: doFilterexception=>condition: 有异常?rollbackTx=>operation: 回滚事务closeSession=>operation: 关闭sessioncleanRestEasyContext=>operation: 清理restEasyContextDataencoding->getSessionFactory->createSession->connection->tx->doFilter->exceptionexception(yes)->closeSessionexception(no)->rollbackTx->closeSession->cleanRestEasyContext</textarea><textarea id="flowchart-1-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-1", options);</script></td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;分析版本: 10.0.0&lt;/p&gt;
&lt;h2 id=&quot;web-xml&quot;&gt;&lt;a href=&quot;#web-xml&quot; class=&quot;headerlink&quot; title=&quot;web.xml&quot;&gt;&lt;/a&gt;web.xml&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;20200508112409320_33
      
    
    </summary>
    
      <category term="Keycloak" scheme="https://www.omingo.com/categories/Keycloak/"/>
    
    
      <category term="keycloak" scheme="https://www.omingo.com/tags/keycloak/"/>
    
  </entry>
  
  <entry>
    <title>k8s上运行mysql</title>
    <link href="https://www.omingo.com/2019/07/12/k8s%E4%B8%8A%E8%BF%90%E8%A1%8Cmysql/"/>
    <id>https://www.omingo.com/2019/07/12/k8s上运行mysql/</id>
    <published>2019-07-12T09:19:17.000Z</published>
    <updated>2019-07-12T09:40:38.072Z</updated>
    
    <content type="html"><![CDATA[<p>k8s中跑mysql要求:</p><ol><li>可通过节点ip访问mysql.</li><li>pod可以访问mysql.</li><li>机器重启后mysql数据不丢失.</li></ol><pre><code class="yml">apiVersion: extensions/v1beta1kind: Deploymentmetadata:  name: mysqlspec:  template:    metadata:      labels:        app: mysql    spec:      nodeName: node1 #指定pod只能调度到node1上      containers:      - image: mysql:5.6        name: mysql        env:        - name: &#39;MYSQL_ROOT_PASSWORD&#39;          value: &#39;root&#39;        - name: &quot;TZ&quot;          value: &quot;Asia/Shanghai&quot; #指定mysql容器的时区为CST,默认为UTC        ports:        - containerPort: 3306        volumeMounts:        - mountPath: /var/lib/mysql          name: mysql-volume      volumes:      - name: mysql-volume # 使用hostPath讲数据文件挂载出来        hostPath:          path: /data/mysql---apiVersion: v1kind: Servicemetadata:   name: mysqlspec:  selector:    app: mysql  type: NodePort  ports:  - port: 3306 # pod中通过 mysql:3306 访问    nodePort: 32306 # 集群外部通过 节点IP:32306访问</code></pre><p>使用hostPath类型的volume持久化数据文件,nodeName固定调度节点,NodePort暴露服务.<br>肥肠地方便.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;k8s中跑mysql要求:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可通过节点ip访问mysql.&lt;/li&gt;
&lt;li&gt;pod可以访问mysql.&lt;/li&gt;
&lt;li&gt;机器重启后mysql数据不丢失.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&quot;yml&quot;&gt;apiVersion:
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.omingo.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s安装指南</title>
    <link href="https://www.omingo.com/2019/06/24/k8s%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"/>
    <id>https://www.omingo.com/2019/06/24/k8s安装指南/</id>
    <published>2019-06-24T07:33:49.000Z</published>
    <updated>2019-06-25T04:01:52.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备机器"><a href="#准备机器" class="headerlink" title="准备机器"></a>准备机器</h2><p>官方要求:</p><ul><li>ubuntu16.04+</li><li>内存≥2G</li><li>cpu≥2</li><li>机器间网络互通</li><li>每个节点的hostname,mac地址,product_uuid要唯一.</li><li>swap要禁用.</li></ul><h3 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h3><table><thead><tr><th>ip</th><th>角色</th><th>hostname</th><th>配置</th><th>系统</th></tr></thead><tbody><tr><td> 192.168.1.36</td><td>master</td><td>node1</td><td>2G/2C</td><td>ubuntu18.04</td></tr><tr><td> 192.168.1.37</td><td>node</td><td>node2</td><td>2G/2C</td><td>ubuntu18.04</td></tr><tr><td> 192.168.1.38</td><td>node</td><td>node3</td><td>2G/2C</td><td>ubuntu18.04</td></tr></tbody></table><p>我使用的是vbox,网络模式使用桥接.安装一个完一个虚拟机之后,复制除另外两个,复制的时候选中”重新初始化所有网卡的MAC地址”<br><img src="/2019/06/24/k8s安装指南/1.png"></p><h3 id="修改主机名称-所有节点"><a href="#修改主机名称-所有节点" class="headerlink" title="修改主机名称(所有节点)"></a>修改主机名称(所有节点)</h3><pre><code class="bash">sudo sed -i &#39;/preserve_hostname: false/c\preserve_hostname: true&#39; /etc/cloud/cloud.cfg &amp;&amp; sudo hostnamectl set-hostname {新hostname}</code></pre><p>退出重新登录后hostname就会改变.<br>参考:<a href="https://askubuntu.com/questions/1028633/host-name-reverts-to-old-name-after-reboot-in-18-04-lts" target="_blank" rel="noopener">修改ubuntu18.04hostname</a></p><h3 id="修改为静态地址-所有节点"><a href="#修改为静态地址-所有节点" class="headerlink" title="修改为静态地址(所有节点)"></a>修改为静态地址(所有节点)</h3><ol><li>执行命令<code>sudo vim /etc/netplan/50-cloud-init.yaml</code></li><li>更改配置<pre><code class="yml">network:   ethernets:       enp0s3:           addresses: [192.168.1.37/24] # 静态ip           gateway4: 192.168.1.1 # 网关           nameservers:                   addresses: [192.168.1.254] #DNS   version: 2</code></pre></li><li>使设置生效<code>sudo netplan apply</code></li></ol><p>参考 <a href="https://ywnz.com/linuxjc/1491.html" target="_blank" rel="noopener">ubuntu 18.04 netplan yaml配置固定IP地址</a></p><h3 id="关闭swap-所有节点"><a href="#关闭swap-所有节点" class="headerlink" title="关闭swap(所有节点)"></a>关闭swap(所有节点)</h3><p><code>sudo swapoff -a</code><br><code>sudo vim /etc/fstab</code> 注释掉 swap那一行,如下:</p><pre><code>UUID=f229223e-9634-11e9-9470-080027aa5c7f / ext4 defaults 0 0#/swap.img    none    swap    sw    0    0  </code></pre><h3 id="检查-mac地址-product-uuid-所有节点"><a href="#检查-mac地址-product-uuid-所有节点" class="headerlink" title="检查 mac地址,product_uuid(所有节点)"></a>检查 mac地址,product_uuid(所有节点)</h3><pre><code class="bash">ip link # 查看macsudo cat /sys/class/dmi/id/product_uuid # 查看product_uuid</code></pre><p>一般情况下不会冲突.(反正我没遇到这种情况☺)</p><h2 id="安装docker-所有节点"><a href="#安装docker-所有节点" class="headerlink" title="安装docker(所有节点)"></a>安装docker(所有节点)</h2><p>国内网络环境,你懂得.<br>使用阿里云提供的方案快速安装: <code>curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</code><br><a href="https://yq.aliyun.com/articles/110806" target="_blank" rel="noopener">Docker CE 镜像源站</a></p><p>请自行配置docker镜像加速.</p><h2 id="安装kubeadm-kubelet-and-kubectl-所有节点"><a href="#安装kubeadm-kubelet-and-kubectl-所有节点" class="headerlink" title="安装kubeadm, kubelet and kubectl(所有节点)"></a>安装kubeadm, kubelet and kubectl(所有节点)</h2><p>安装k8s需要安装这三个包:</p><table><thead><tr><th>名称</th><th>作用 </th></tr></thead><tbody><tr><td> kubeadm</td><td>用来引导集群 </td></tr><tr><td> kubelet</td><td>在群集中的所有计算机上运行的组件，并执行诸如启动pod和容器之类的操作</td></tr><tr><td> kubectl</td><td>用来和集群通信的命令行工具</td></tr></tbody></table><p>国内网络环境,这回应该懂了吧…</p><pre><code class="bash"># 使用root操作sudo su apt-get update &amp;&amp; apt-get install -y apt-transport-httpscurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF  apt-get updateapt-get install -y kubelet kubeadm kubectl</code></pre><h3 id="准备镜像-所有节点"><a href="#准备镜像-所有节点" class="headerlink" title="准备镜像(所有节点)"></a>准备镜像(所有节点)</h3><p>集群初始化的时候需要从k8s.gcr.io拉取镜像,但是国内网络环境,你懂得.</p><ol><li><code>kubeadm config images list</code> 查看使用到的镜像<pre><code>kubeadm config images listk8s.gcr.io/kube-apiserver:v1.15.0k8s.gcr.io/kube-controller-manager:v1.15.0k8s.gcr.io/kube-scheduler:v1.15.0k8s.gcr.io/kube-proxy:v1.15.0k8s.gcr.io/pause:3.1k8s.gcr.io/etcd:3.3.10k8s.gcr.io/coredns:1.3.1</code></pre></li><li>手动获取一下镜像<pre><code>#上面那一堆复制下来images=( k8s.gcr.io/kube-apiserver:v1.15.0 k8s.gcr.io/kube-controller-manager:v1.15.0 k8s.gcr.io/kube-scheduler:v1.15.0 k8s.gcr.io/kube-proxy:v1.15.0 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.10 k8s.gcr.io/coredns:1.3.1)for imageName in ${images[@]} ; do imageName=${imageName##*/} docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageNamedone </code></pre><h2 id="初始化集群-master节点"><a href="#初始化集群-master节点" class="headerlink" title="初始化集群(master节点)"></a>初始化集群(master节点)</h2></li></ol><pre><code># 因为使用flannel网络插件,需要在kubeadm init 时设置 --pod-network-cidr=10.244.0.0/16sudo kubeadm init --pod-network-cidr=10.244.0.0/16</code></pre><h2 id="配置授权信息-master节点"><a href="#配置授权信息-master节点" class="headerlink" title="配置授权信息(master节点)"></a>配置授权信息(master节点)</h2><p>集群初始化后有提示</p><pre><code>mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><h2 id="添加网络插件-master节点"><a href="#添加网络插件-master节点" class="headerlink" title="添加网络插件(master节点)"></a>添加网络插件(master节点)</h2><p>执行<code>kubectl get pods -A</code> 会发现coredns状态为pending.以为还没有安装网络插件,所有和网络相关的pod都会为pending.<br>集群初始化完成后也有提示<code>You should now deploy a pod network to the cluster.</code><br>添加网络插件:</p><pre><code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code></pre><p>稍等片刻,再次执行 <code>kubectl get pods -A</code> ,所有POD 都running了.</p><h2 id="设置master节点也可以运行Pod"><a href="#设置master节点也可以运行Pod" class="headerlink" title="设置master节点也可以运行Pod"></a>设置master节点也可以运行Pod</h2><p>kubernetes官方默认策略是worker节点运行Pod，master节点不运行Pod。如果只是为了开发或者其他目的而需要部署单节点集群，可以通过以下的命令设置<br><code>kubectl taint nodes --all node-role.kubernetes.io/master-</code></p><h2 id="加入节点-worker节点"><a href="#加入节点-worker节点" class="headerlink" title="加入节点(worker节点)"></a>加入节点(worker节点)</h2><p>集群初始化完成后也有提示:</p><pre><code>Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.1.36:6443 --token 9wujqe.xfc5msp9l3i9g9s8 \    --discovery-token-ca-cert-hash sha256:1c67699dbf329cceff693a37a6b3f2c4d706901673343a24c872d802a7ed3433</code></pre><h2 id="测试一下"><a href="#测试一下" class="headerlink" title="测试一下"></a>测试一下</h2><p>在master执行:</p><pre><code>kubectl get nodes #此时应该有三个节点NAME    STATUS   ROLES    AGE    VERSIONnode1   Ready    master   36m    v1.15.0node2   Ready    &lt;none&gt;   8m2s   v1.15.0node3   Ready    &lt;none&gt;   29s    v1.15.0</code></pre><p>创建个deployment试试</p><pre><code>kubectl run my-nginx --image=nginx --replicas=3 --port=80# 稍等片刻kubectl get pods -o wide# 应该这样的NAME                        READY   STATUS    RESTARTS   AGE   IP           NODE    NOMINATED NODE   READINESS GATESmy-nginx-756fb87568-ssxj5   1/1     Running   0          94s   10.244.0.4   node1   &lt;none&gt;           &lt;none&gt;my-nginx-756fb87568-x2mtk   1/1     Running   0          94s   10.244.2.2   node3   &lt;none&gt;           &lt;none&gt;my-nginx-756fb87568-zkjxj   1/1     Running   0          94s   10.244.1.2   node2   &lt;none&gt;           &lt;none&gt;</code></pre><p>创建个service试试</p><pre><code>kubectl expose deployment my-nginx --name=my-nginx --port 80 --target-port 80 --external-ip 192.168.1.36</code></pre><p>打开浏览器访问一下 192.168.1.36,nginx首页.<br><img src="/2019/06/24/k8s安装指南/2.png"><br>可以愉快的玩耍了.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;准备机器&quot;&gt;&lt;a href=&quot;#准备机器&quot; class=&quot;headerlink&quot; title=&quot;准备机器&quot;&gt;&lt;/a&gt;准备机器&lt;/h2&gt;&lt;p&gt;官方要求:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ubuntu16.04+&lt;/li&gt;
&lt;li&gt;内存≥2G&lt;/li&gt;
&lt;li&gt;cpu≥2&lt;
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.omingo.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>国内microk8s安装指南</title>
    <link href="https://www.omingo.com/2019/06/21/%E5%9B%BD%E5%86%85microk8s%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"/>
    <id>https://www.omingo.com/2019/06/21/国内microk8s安装指南/</id>
    <published>2019-06-21T02:08:30.000Z</published>
    <updated>2019-06-21T02:38:28.403Z</updated>
    
    <content type="html"><![CDATA[<p>microk8s 是一个专门为开发人员设计的轻量级单节点k8s包.可以用来替代minikube进行学习.</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>由gfw,安装microk8s后会发现docker image无法下载的问题.(详细安装步骤参见 <a href="https://microk8s.io/#quick-start" target="_blank" rel="noopener">https://microk8s.io/#quick-start</a>)</p><p><code>microk8s.kubectl describe pods -A</code> 会有错误提示<br> <em>[ERROR ImagePull]: failed to pull image [k8s.gcr.io/pause:3.1]</em></p><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><pre><code class="bash">docker pull mirrorgooglecontainers/pause:3.1docker pull mirrorgooglecontainers/heapster-influxdb-amd64:v1.3.3docker pull mirrorgooglecontainers/heapster-grafana-amd64:v4.4.3docker pull mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.8.3docker pull mirrorgooglecontainers/heapster-amd64:v1.5.2docker pull mirrorgooglecontainers/k8s-dns-dnsmasq-nanny-amd64:1.14.7docker pull mirrorgooglecontainers/k8s-dns-kube-dns-amd64:1.14.7docker pull mirrorgooglecontainers/k8s-dns-sidecar-amd64:1.14.7docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1docker tag mirrorgooglecontainers/heapster-influxdb-amd64:v1.3.3 k8s.gcr.io/heapster-influxdb-amd64:v1.3.3docker tag mirrorgooglecontainers/heapster-grafana-amd64:v4.4.3 k8s.gcr.io/heapster-grafana-amd64:v4.4.3docker tag mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.8.3 k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.3docker tag mirrorgooglecontainers/heapster-amd64:v1.5.2 k8s.gcr.io/heapster-amd64:v1.5.2docker tag mirrorgooglecontainers/k8s-dns-dnsmasq-nanny-amd64:1.14.7 gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7docker tag mirrorgooglecontainers/k8s-dns-kube-dns-amd64:1.14.7 gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.7docker tag mirrorgooglecontainers/k8s-dns-sidecar-amd64:1.14.7 gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.7docker save k8s.gcr.io/pause &gt; pause.tardocker save k8s.gcr.io/heapster-influxdb-amd64 &gt; heapster-influxdb-amd64.tardocker save k8s.gcr.io/heapster-grafana-amd64 &gt; heapster-grafana-amd64.tardocker save k8s.gcr.io/kubernetes-dashboard-amd64 &gt; kubernetes-dashboard-amd64.tardocker save k8s.gcr.io/heapster-amd64 &gt; heapster-amd64.tardocker save gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 &gt; k8s-dns-dnsmasq-nanny-amd64.tardocker save gcr.io/google_containers/k8s-dns-kube-dns-amd64 &gt; k8s-dns-kube-dns-amd64.tardocker save gcr.io/google_containers/k8s-dns-sidecar-amd64 &gt; k8s-dns-sidecar-amd64.tarmicrok8s.ctr -n k8s.io image import pause.tarmicrok8s.ctr -n k8s.io image import heapster-influxdb-amd64.tarmicrok8s.ctr -n k8s.io image import heapster-grafana-amd64.tarmicrok8s.ctr -n k8s.io image import kubernetes-dashboard-amd64.tarmicrok8s.ctr -n k8s.io image import heapster-amd64.tarmicrok8s.ctr -n k8s.io image import k8s-dns-dnsmasq-nanny-amd64.tarmicrok8s.ctr -n k8s.io image import k8s-dns-kube-dns-amd64.tarmicrok8s.ctr -n k8s.io image import k8s-dns-sidecar-amd64.tar</code></pre><p>然后就可以愉快的玩耍了.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;microk8s 是一个专门为开发人员设计的轻量级单节点k8s包.可以用来替代minikube进行学习.&lt;/p&gt;
&lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;由gfw,安装mic
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.omingo.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>使用log-pilot收集docker容器日志</title>
    <link href="https://www.omingo.com/2019/05/21/%E4%BD%BF%E7%94%A8log-pilot%E6%94%B6%E9%9B%86docker%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97/"/>
    <id>https://www.omingo.com/2019/05/21/使用log-pilot收集docker容器日志/</id>
    <published>2019-05-21T08:25:15.000Z</published>
    <updated>2019-05-21T09:06:48.997Z</updated>
    
    <content type="html"><![CDATA[<p>本文档介绍一款新的 Docker 日志收集工具：log-pilot。log-pilot 是阿里云提供的日志收集镜像。我们可以在每台机器上部署一个 log-pilot 实例，就可以收集机器上所有 Docker 应用日志。(注意：只支持Linux版本的Docker，不支持Windows/Mac版)。</p><p>log-pilot 具有如下特性：</p><ul><li>一个单独的 log 进程收集机器上所有容器的日志。不需要为每个容器启动一个 log 进程。</li><li>支持文件日志和 stdout。docker log dirver 亦或 logspout 只能处理 stdout，log-pilot 不仅支持收集 stdout 日志，还可以收集文件日志。</li><li>声明式配置。当您的容器有日志要收集，只要通过 label 声明要收集的日志文件的路径，无需改动其他任何配置，log-pilot 就会自动收集新容器的日志。</li><li>支持多种日志存储方式。无论是强大的阿里云日志服务，还是比较流行的 elasticsearch 组合，甚至是 graylog，log-pilot 都能把日志投递到正确的地点。</li><li><p>开源。log-pilot 完全开源，您可以从 Git项目地址 <a href="https://github.com/AliyunContainerService/log-pilot" target="_blank" rel="noopener">下载代码</a>。如果现有的功能不能满足您的需要，欢迎提 issue。</p><img src="/2019/05/21/使用log-pilot收集docker容器日志/1.png"></li></ul><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>先有应用使用单机docker部署,需要将docker容器产生的日志发送到kafka.</p><p>首先部署log-pilot镜像,用来感知容器日志并发送日志到目的地:</p><pre><code>docker run --name log-pilot -d \-v /var/run/docker.sock:/var/run/docker.sock \-v /etc/localtime:/etc/localtime \-v /:/host:ro \--cap-add SYS_ADMIN \-e LOGGING_OUTPUT=kafka \ #选择输入类型 kafka-e KAFKA_BROKERS=kafka:9092 \ # 配置kafka的地址registry.cn-hangzhou.aliyuncs.com/acs/log-pilot:0.9.5-filebeat</code></pre><p>运行docker应用的时候只需要增加标签 aliyun.$name.*:<br>如:</p><pre><code>docker run -it --rm -p 10080:8080 \-v /usr/local/tomcat/logs \--label aliyun.logs.catalina=stdout \ --label aliyun.logs.access=/usr/local/tomcat/logs/localhost_access_log.*.txt \tomcat</code></pre><p>还可以自定义输入的target:<br>aliyun.$name.target=&lt;target&gt;<br>&lt;target&gt;:自定义字符串,分别指代:</p><ol><li>eleasticsearch-&gt;index</li><li>kafka-&gt;topic</li></ol><p>参考文章:<br><a href="https://yq.aliyun.com/articles/674327" target="_blank" rel="noopener">日志采集利器</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文档介绍一款新的 Docker 日志收集工具：log-pilot。log-pilot 是阿里云提供的日志收集镜像。我们可以在每台机器上部署一个 log-pilot 实例，就可以收集机器上所有 Docker 应用日志。(注意：只支持Linux版本的Docker，不支持Win
      
    
    </summary>
    
    
      <category term="日志" scheme="https://www.omingo.com/tags/%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>兄弟俩畅游Tomcat城市的SpringMVC科技园区</title>
    <link href="https://www.omingo.com/2019/05/09/%E5%85%84%E5%BC%9F%E4%BF%A9%E7%95%85%E6%B8%B8Tomcat%E5%9F%8E%E5%B8%82%E7%9A%84SpringMVC%E7%A7%91%E6%8A%80%E5%9B%AD%E5%8C%BA/"/>
    <id>https://www.omingo.com/2019/05/09/兄弟俩畅游Tomcat城市的SpringMVC科技园区/</id>
    <published>2019-05-09T07:44:12.000Z</published>
    <updated>2019-05-09T08:28:24.159Z</updated>
    
    <content type="html"><![CDATA[<p>今天看到一片文章挺有意思的,转了过来.</p><p>来自公众号：编程新说  李新杰</p><h2 id="Tomcat城市"><a href="#Tomcat城市" class="headerlink" title="Tomcat城市"></a>Tomcat城市</h2><p>Tomcat这座城市的历史相当悠久了，经历过几次大的变迁后，呈现出非常明显的地域特征。<br>从城市往西走，过了城乡结合部以后，可以说是满目疮痍、一片破败，这就是Servlet地区，这座城市一开始就是从这个地方发展起来的。<br>哎，这都是很多年前的老黄历了，只有一些老人才知道这些，现在的年轻人都不到这个地方来了，于是就荒芜了，快成无人区了。<br>城市的中央是Struts地区，人们习惯称它为老城区。矮矮的居民楼，窄窄的街道，三五成群的老旧工厂。<br>虽然现在没落了，但是置身其中，你依然能够感受到它曾经辉煌过的痕迹，那时也应该是灯红酒绿、人声鼎沸、好不热闹。<br>现在这里只剩下一些老年人了，年轻人觉得这里太陈旧了，都纷纷搬走了，偶尔能见到几个，那是回来看望父母的。<br>从城市往东走，出了老城进入新区，高楼大厦、玻璃幕墙，大宽马路、人流成河。红灯绿灯、南来北往，车声人声、声声不息。<br>这里充满了大量的年轻人，节奏感、时尚感、科技感，有梦想、有压力、有希望。没错，这就是大名鼎鼎、闻名遐迩的SpringMVC地区。<br>技术的发展就像城市的变迁，有新区就有老城。所谓长江后浪推前浪，一浪更比一浪浪，真是够浪，嗯，golang。</p><blockquote><p>第一代web应用Jsp+Servlet，现在基本没人用了，成了无人区了。<br>第二代web应用Struts1.x、Struts2，曾经辉煌时很多人用，现在都是进入维护期的老项目了，就像老城区。<br>第三代web应用SpringMVC，现在如日中天，依然是主战场，就如同城市的新区。</p><footer><strong>[编程新说]</strong></footer></blockquote><p>不过SpringMVC并非固若金汤，它的挑战者已经出现，就是响应式web应用，它现在不仅要面临外患，还有来自内忧的困扰。</p><h2 id="破旧的火车站"><a href="#破旧的火车站" class="headerlink" title="破旧的火车站"></a>破旧的火车站</h2><p>request奉主人之命，坐了“一夜”的火车，“长途跋涉”后来到了tomcat城市，按照约定，他的弟弟response会来这里接他。request刚下了车，他弟弟就迎了上来，没想到他跑到站台上来接自己了。<br>request边走边四处打量着，这座车站虽然略显破旧，但结构设计合理，层层叠叠、环环相扣，真是建筑之美啊。<br>他突然意识到自己是第一次来这里，还不知道路怎么走，看到不远处有一老者在扫地，打算前去问路。眼看就要到了，不料被四个人“截胡”了。<br>其中两个人说他们要找一个叫MyServlet的人，老者说出门往西走就行了。另外两个人说要找一个叫<code>FilterDispatcher</code>的人，老者说出门往前走就行了。<br>看着他们四人离去的背影，老者无奈地摇了摇头，又自顾自地开始扫地。request上去询问为何这般，老者解释道，这四位可是稀客啊，现在像他们这样的人已经很少了。几乎都是去找<code>DispatcherServlet</code>的人。<br>request说道，我们就是要去找<code>DispatcherServlet</code>呀，老者说，出门跟着人流走，保证能找到。为了礼貌，request询问了老者的姓名，老者说，他是Wrapper，在这里工作十几年了。<br>request和response跟老者道谢后，就离开了。出门后，好不容易挤上了一辆公交，一路向东奔去。</p><blockquote><p><em>MyServlet</em> 一般是一个刚毕业的学生起的名字。<br><em>FilterDispatcher</em> 是Struts2的核心控制器。<br><em>DispatcherServlet</em> 是SpringMVC的核心控制器。<br><em>Wrapper</em> 是Tomcat内部的一种容器组件，负责<em>Servlet</em>的调用执行。</p><footer><strong>[编程新说]</strong></footer></blockquote><h2 id="SpringMVC科技园区"><a href="#SpringMVC科技园区" class="headerlink" title="SpringMVC科技园区"></a>SpringMVC科技园区</h2><p> “前方到站SpringMVC科技园，有下车的乘客，请携带好随身物品，从后门下车”，两兄弟好不容易挤到后门，下车了。<br>眼前的这个科技园四四方方，里面的高大建筑布局合理。门前的宽大道路干净笔直，向南北无限延伸。旁边的小路绿树成荫、鲜花满地。<br>这里的一切都极具现代化都市气息，兄弟俩早已忘我。一阵急促的嘈杂声响起，哦，原来是绿灯亮了，可以过马路了，随机又淹没在人群中。<br>两兄弟在园区门口被保安拦下，“恁俩是弄啥嘞？”，保安问道。两兄弟一听，咦，河南人，心里乐了。说道，“老乡，俺是来找一个叫<code>DispatcherServlet</code>的人”。保安道，“那中，他一般都可忙啦，恁俩先去那边树荫下凉快凉快吧”。<br>一会儿功夫，有一个中年微胖男人来到了门口，就是他了。两兄弟表明来意后，request递上了一张“介绍信”，上面似乎写着：</p><pre><code>POST /users HTTP/1.1Content-Type: application/x-wwww-form-urlencodedAccept: application/jsonusername=abc&amp;password=1qaz@WSX&amp;email=xyz@456.com&amp;age=30</code></pre><p><code>DispatcherServlet</code>看后，心里暗骂一句，这是哪个小兔崽子在写着玩呢。不过人既然已经来了，那就按照程序走吧。<br>他就带着两兄弟来到了一个房间门口，说先进去检查一下，看看有没有“携带大件行李物品”。只见response准备进去，一把被他拉回来，说你不用去，只要你哥哥去就行了。<br>request来到门前，只见上面写着checkMultipart，推门而入，有个叫<code>MultipartResolver</code>的工作人员，正准备对他搜查，一看<code>Content-Type</code>，嘟囔着说原来只是普通表单提交没有附件，随即放弃了对request的检查，让他直接出去了。<br>request一脸懵逼，他原以为来到这里后，会有人专门带着他参观，给他讲解，端茶倒水啥的。谁知就像进了医院体检一样，拿个“单子”乱跑。<br>正在郁闷着的request在走过一个叫getHandler的房间门口时，被叫停了，他知道又该进去被检查了。一个叫<code>RequestMappingHandlerMapping</code>的家伙坐在电脑后面，request赶紧递上自己的单子。<br>那个家伙瞄了一眼单子后，在输入框里敲上“POST /users”关键字，点击搜索按钮，只见结果的第一条就是一个叫<code>UserController</code>的小伙子。并把这个小伙子的信息打印到一张纸上给了request。<br>request接过纸，边往外走边看，只见上面写着：</p><pre><code>HandlerExecutionChain:  handler:    HandlerMethod:      beanType: UserController      method: registerUser      parameters: [User]  interceptors: null</code></pre><p>request又是一脸懵逼，这都什么玩意儿呀。不过定睛一看，发现了熟悉的字眼儿。如UserController、registerUser、User。<br>request隐隐约约当中记得自己的主人写过一些和他们相关的东西，好像是这样的：</p><pre><code class="java">@RequestMapping(&quot;/users&quot;)@RestControllerpublic class UserController{  @Autowired  private IUserService userService;  @PostMapping  public RestResult registerUser(@ModelAttribute(&quot;user&quot;)User user){    userService.addUser(user);    return new RestResult(0,&quot;seccess&quot;);  }}public class User{  private String username;  private String password;  private String email;  private Integer age;}public class RestResult{  private Integer code;  private String desc;}</code></pre><p>此时，request仿佛明白了，刚才那个家伙根据我的“单子”，使用电脑搜索，为我开了个“方子”。说<code>UserController</code>这个小伙子的<code>registerUser</code>方法“可以治我的病”，其中<code>User</code>是方法入参。<br>request正准备沾沾自喜，怎么脑门突然一阵疼痛，莫非是得意忘形受了诅咒，哦，不是，是撞到门上了。揉了揉脑袋，便出了门。<br>三人一行继续往前走，request心里明白，现在这充其量叫作“做检查”，后面非给我来一个“大的修里”不可。又在一个叫做<code>getHandlerAdapter</code>的房间门口停住了。<br>不过这次两兄弟都在外面等着，是<code>DispatcherServlet</code>亲自拿着给request开的“方子”进去了。不一会他就出来了，又带出来一位叫<code>RequestMappingHandlerAdapter</code>的人，说这位是高级技工，由他来完成一部分核心工作。<br>这位高级技工带着两兄弟向自己的地盘走去，来到了一个写着handle的门前，推开门一起进入。这是一个非常大的房间，里面有好多的工作人员和机器设备，两兄弟明白，是时候了，重大的事情将在这里发生。<br>高级技工让两兄弟躺到工作台上，然后让所有人员各就各位，接着就是“生死看淡，不服就干”，于是，一切井然有序地开始了。<br>一个叫<code>ServletInvocableHandlerMethod</code>的家伙是本次的主要操盘手，他依次点名了自己的队友和检查了要用的设备，一切正常，下面正式开始了。<br>操盘手拿到给request开的“方子”，发现需要调用<code>registerUser</code>方法，于是先通过反射拿到这个方法的参数，再经过一番解析后变成了<code>MethodParameter</code>类型啦，对，它就表示方法的参数。<br>操盘手让他的队友<code>ParameterNameDiscoverer</code>去查看下参数的名字是什么，队友拿到参数，惊奇地发现上面有个<code>@ModelAttribute(&quot;user&quot;)</code>注解，于是从注解中读到了user，它就是参数的名字了。<br>操盘手又让他的队友<code>HandlerMethodArgumentResolver</code>去想办法把参数值搞定，队友也发现了<code>@ModelAttribute(&quot;user&quot;)</code>注解，说明这个参数是个模型数据，而且不是简单类型。于是先打开设备<code>ModelAndViewContainer</code>，发现设备里并没有一个叫user的数据。<br>队友明白，需要自己来生成这样的一个参数了。先拿到参数类型<code>User</code>，然后反射一下构造函数，发现正好有个默认无参的，通过它就new出了一个<code>User</code>类型的对象了。<br>队友接着反射一下它的属性，发现有4个，<em>username</em>、<em>password</em>、<em>email</em>、<em>age</em>。接着从request中恰巧能找出这4个名称的值，使用<code>WebDataBinderFactory</code>设备把数据类型合理转化后，设置给了user对象。这样队友就把参数值给准备好了。<br>有了<code>registerUser</code>方法和<code>user</code>参数后，还要知道在哪个对象上调用才行啊，于是操盘手根据方法所在的类型<code>UserController</code>，去容器中找到它的bean实例，接着就在该实例上通过反射发起了方法调用，传进去入参，并获取返回结果。<br>操盘手拿到返回结果，简单检查后发现返回结果不为null，再检查request的弟弟response，发现没有出现错误，而且还没有执行结束。于是在ModelAndViewContainer设备上把该请求标记为尚未处理完。<br>然后把返回结果交给队友<code>HandlerMethodReturnValueHandler</code>去处理，队友发现方法所在的类<code>UserController</code>上标有<code>@ResponseBody</code>注解（是作为<code>@RestController</code>的元注解出现的），瞬间就明白方法的返回值是直接作为web请求的响应的。<br>由于方法的返回值是要直接写入response的，所以就完事了，不用考虑视图解析这一块了。因此队友就在<code>ModelAndViewContainer</code>设备上把本次请求标记为已处理完成。<br>接着就把方法的返回值交给自己的好朋友<code>HttpMessageConverter</code>去处理，好朋友看了request的“单子”一眼，发现上面有<code>Accept：application/json</code>，瞬间也明白了，原来他想要的是JSON格式呀。<br>于是把方法返回值发给合作伙伴Jackson，不一会给他发回了结果，<code>{&quot;code&quot;:0,&quot;desc&quot;:&quot;success&quot;}</code>，好朋友把这个结果甩给了response，叫他拿好了。<br>好朋友完成了队友的任务，队友完成了操盘手的任务，操盘手向高级技工报告，任务已成功完成，请检阅。<br>高级技工本来打算输出一个<code>ModelAndView</code>作为处理结果呢，一检查<code>ModelAndViewContainer</code>设备发现请求已被处理完了。罢了，那就返回一个null吧。<br>门开了，两兄弟出来了，哥哥request已被“消耗殆尽”，弟弟response“满载而归”。<code>DispatcherServlet</code>早已在此等候，他看到高级技工手里只有一个null，于是记录了一句话，“No view rendering, null ModelAndView returned.”。<br>两兄弟和<code>DispatcherServlet</code>道谢后来到了园区大门口，接着和老乡保安挥手告别。此时天色已晚，挤上一辆公交车后，直奔火车站而去。</p><h2 id="就此一别，再无相见"><a href="#就此一别，再无相见" class="headerlink" title="就此一别，再无相见"></a>就此一别，再无相见</h2><p>一路摇摇晃晃来到火车站，天已完全黑透了。返程的列车早已整装待发，弟弟response拉着哥哥的手准备一起上车，被哥哥拒绝了，哥哥说按照剧情应该只有你一个人回去。我的使命已完成了。<br>弟弟并不明白哥哥是什么意思，就问道那我们还能不能再见面。哥哥笑着说傻孩子，“当然可以了”。弟弟高兴地跳上了车。<br>伴着一声长鸣，列车启动，兄弟俩互相挥手告别，列车渐渐消失在黑夜的黑中。弟弟没有看到哥哥微笑的眼角流下了流水。<br>只有哥哥心里明白，他和弟弟，就此一别，再无相见。转身向车站外走去，看到那个老者依然在自顾自的扫着地。<br>黑白无常拿着脚镣手铐，早已在此“恭候多时”，有气无力的request全然无法反抗，任由这“二鬼”拖着去“阴曹地府”接受JVM的轮回。<br>也许老天不愿意看到一个光荣完成使命的人就这般的“烟消玉损”，就派出了钟馗来解救他。钟馗打跑了黑白无常，希望带request“永生”。<br>request婉言拒绝，说我非“三界五行”之外，我依然是凡人，依然有自己的宿命。这是任何人都无法逃离的自然规律。<br>顷刻，一束白光从天而降，洒满request的全身，只见request张开双臂，身轻如燕般的飞向光的源头，不一会便没有了踪迹。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天看到一片文章挺有意思的,转了过来.&lt;/p&gt;
&lt;p&gt;来自公众号：编程新说  李新杰&lt;/p&gt;
&lt;h2 id=&quot;Tomcat城市&quot;&gt;&lt;a href=&quot;#Tomcat城市&quot; class=&quot;headerlink&quot; title=&quot;Tomcat城市&quot;&gt;&lt;/a&gt;Tomcat城市&lt;/h2
      
    
    </summary>
    
      <category term="springMVC" scheme="https://www.omingo.com/categories/springMVC/"/>
    
    
      <category term="转载" scheme="https://www.omingo.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>微服务不停服升级</title>
    <link href="https://www.omingo.com/2019/05/09/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%8D%E5%81%9C%E6%9C%8D%E5%8D%87%E7%BA%A7/"/>
    <id>https://www.omingo.com/2019/05/09/微服务不停服升级/</id>
    <published>2019-05-09T06:41:32.000Z</published>
    <updated>2019-05-09T07:36:28.465Z</updated>
    
    <content type="html"><![CDATA[<p>有时候我们会给生产环境修复一些比较严重的bug,有没有一种操作可以不停服进行系统升级呢?<br>答案是: <strong>有的</strong>.</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>生产环境部署在阿里云acs-swarm上.<br>服务注册使用eureka.</p><h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><p>首先新增新版本的服务实例到生产环境,待新版本服务开始服务之后,通知注册中心下线老版本服务(此时老版本服务不停机,还可以提供服务,只是不会在收到新的请求了),观察监控 等待老版本服务处理完所有请求之后,停机老版本服务,至此完成不停服升级.<br>原理挺简单,关键看操作.</p><h2 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h2><ol><li><p>打包要升级的服务,并推送到阿里云镜像服务.</p></li><li><p>进入阿里云后台容器服务,选择服务所在集群,选择相应的应用 点变更配置.<br>找到相应的服务,修改一下服务名称,比如 user-service 修改成 user-service-1,在修改一下服务镜像的版本号,还有acs应用的版本号.<br><strong>注意发布类型要选蓝绿发布</strong></p><img src="/2019/05/09/微服务不停服升级/1.png"><p>确定之后稍等片刻,你会发现,你的容器服务列表新增了一个user-service-1的服务. eureka服务器上user-service的实例也多了一个.</p></li><li><p>通知注册中心下线老版本服务</p><pre><code class="bash">curl -X PUT http://eureka-server:8761/eureka/app/{SERVICE-NAME}/{SERVICE-ID}/status?value=OUT_OF_SERVICE</code></pre><p>把{}中的内容替换成实际内容.<br>你会发现eureka会给这个实例标记一个 红色的 OUT_OF_SERVICE,这样eureka client就不会获取到这个实例的注册信息了,网关也不会讲流量转发到这个实例上来了.</p></li><li><p>看监控下线老版本服务.<br>你会发现老服务的流量会越来越少.</p><img src="/2019/05/09/微服务不停服升级/2.png"><p>当老服务处理完所有请求的时候,到阿里云acs控制台,选择确认发布.</p></li></ol><p>搞定,收工.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;有时候我们会给生产环境修复一些比较严重的bug,有没有一种操作可以不停服进行系统升级呢?&lt;br&gt;答案是: &lt;strong&gt;有的&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="微服务" scheme="https://www.omingo.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="升级" scheme="https://www.omingo.com/tags/%E5%8D%87%E7%BA%A7/"/>
    
  </entry>
  
  <entry>
    <title>spring-data-jpa进阶用法之QueryDSL</title>
    <link href="https://www.omingo.com/2019/05/07/spring-data-jpa%E8%BF%9B%E9%98%B6%E7%94%A8%E6%B3%95%E4%B9%8BQueryDSL/"/>
    <id>https://www.omingo.com/2019/05/07/spring-data-jpa进阶用法之QueryDSL/</id>
    <published>2019-05-07T15:16:24.000Z</published>
    <updated>2019-05-08T01:10:11.942Z</updated>
    
    <content type="html"><![CDATA[<p>很多列表查询接口都会有很多复杂的过滤条件。一般都会在controller里面各种拼接条件然后在持久层写好多针对性的查询接口，导致代码可读性差，实现不够优雅。</p><h3 id="QueryDSL"><a href="#QueryDSL" class="headerlink" title="QueryDSL"></a>QueryDSL</h3><p>其实QueryDsl可以很优雅的解决上述场景遇到的问题，QueryDSL是一个Java语言编写的通用查询框架。spring-data-jpa对QueryDsl提供了良好的支持。同时spring-data-jpa也针对web做了一些扩展支持。具体可以参考<a href="https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#core.extensions.querydsl" target="_blank" rel="noopener">spring-data-jpa的官方文档</a>。</p><h3 id="spring-data-jpa的支持"><a href="#spring-data-jpa的支持" class="headerlink" title="spring-data-jpa的支持"></a>spring-data-jpa的支持</h3><p>持久层repository继承<code>QuerydslPredicateExecutor</code>，即可使用QueryDsl查询。</p><pre><code class="java">interface UserRepository extends CrudRepository&lt;User, Long&gt;, QuerydslPredicateExecutor&lt;User&gt; {}Predicate predicate = user.firstname.equalsIgnoreCase(&quot;dave&quot;)    .and(user.lastname.startsWithIgnoreCase(&quot;mathews&quot;));userRepository.findAll(predicate);</code></pre><p>web层可以使用 @QuerydslPredicate 标注Predicate。</p><pre><code class="java">@Controllerclass UserController {  @Autowired UserRepository repository;  @RequestMapping(value = &quot;/&quot;, method = RequestMethod.GET)  String index(Model model, @QuerydslPredicate(root = User.class) Predicate predicate,              Pageable pageable, @RequestParam MultiValueMap&lt;String, String&gt; parameters) {    model.addAttribute(&quot;users&quot;, repository.findAll(predicate, pageable));    return &quot;index&quot;;  }}</code></pre><p>这样包含 ?firstname=Dave&amp;lastname=Matthews的查询将会被<code>QuerydslPredicateArgumentResolver</code>解析成 <code>QUser.user.firstname.eq(&quot;Dave&quot;).and(QUser.user.lastname.eq(&quot;Matthews&quot;))</code></p><p>有时候我们的参数并不是和实体的属性一一对应，甚至我们需要隐藏一些不可以用来查询的属性。</p><h3 id="自定义绑定关系"><a href="#自定义绑定关系" class="headerlink" title="自定义绑定关系"></a>自定义绑定关系</h3><p>我们可一通过实现 <code>QuerydslBinderCustomizer</code>这个接口来自定义参数的绑定关系。</p><pre><code class="java">CustomUserQuerydslBinder implements QuerydslBinderCustomizer&lt;QUser&gt; {    @Override    public void customize(QuerydslBindings querydslBindings, QUser qUser) {      //自定义绑定关系      querydslBindings.excludeUnlistedProperties(true);//使用白名单模式      querydslBindings.including( //设置属性白名单            qUser.id,            qUser.name      );      //自定义参数的绑定       querydslBindings.bind(Expressions.stringPath(&quot;sex&quot;)).as(&quot;type&quot;).first((path,value)-&gt;            path.eq(value)        );    }}</code></pre><p>然后在 <code>@QuerydslPredicate(bindings=CustomUserQuerydslBinder.class,root=User.class)</code>中指定。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;很多列表查询接口都会有很多复杂的过滤条件。一般都会在controller里面各种拼接条件然后在持久层写好多针对性的查询接口，导致代码可读性差，实现不够优雅。&lt;/p&gt;
&lt;h3 id=&quot;QueryDSL&quot;&gt;&lt;a href=&quot;#QueryDSL&quot; class=&quot;headerlin
      
    
    </summary>
    
      <category term="jpa" scheme="https://www.omingo.com/categories/jpa/"/>
    
    
      <category term="qdsl" scheme="https://www.omingo.com/tags/qdsl/"/>
    
      <category term="jpa" scheme="https://www.omingo.com/tags/jpa/"/>
    
  </entry>
  
  <entry>
    <title>非spring-cloud项目增加hystrix监控</title>
    <link href="https://www.omingo.com/2019/05/07/%E9%9D%9Espring-cloud%E9%A1%B9%E7%9B%AE%E5%A2%9E%E5%8A%A0hystrix%E7%9B%91%E6%8E%A7/"/>
    <id>https://www.omingo.com/2019/05/07/非spring-cloud项目增加hystrix监控/</id>
    <published>2019-05-07T09:11:30.000Z</published>
    <updated>2019-05-07T09:12:45.582Z</updated>
    
    <content type="html"><![CDATA[<h2 id="增加依赖"><a href="#增加依赖" class="headerlink" title="增加依赖"></a>增加依赖</h2><p>pom文件中</p><pre><code class="xml"> &lt;dependency&gt;  &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt;  &lt;artifactId&gt;hystrix-metrics-event-stream&lt;/artifactId&gt;  &lt;version&gt;${hystrix.version}&lt;/version&gt; &lt;/dependency&gt;</code></pre><h2 id="添加servlet"><a href="#添加servlet" class="headerlink" title="添加servlet"></a>添加servlet</h2><p>web.xml 中</p><pre><code class="xml">  &lt;servlet&gt;    &lt;display-name&gt;HystrixMetricsStreamServlet&lt;/display-name&gt;    &lt;servlet-name&gt;HystrixMetricsStreamServlet&lt;/servlet-name&gt;    &lt;servlet-class&gt;com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet    &lt;/servlet-class&gt;  &lt;/servlet&gt;  &lt;servlet-mapping&gt;    &lt;servlet-name&gt;HystrixMetricsStreamServlet&lt;/servlet-name&gt;    &lt;url-pattern&gt;/hystrix.stream&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;</code></pre><h2 id="增加Basic安全认证"><a href="#增加Basic安全认证" class="headerlink" title="增加Basic安全认证"></a>增加Basic安全认证</h2><p>web.xml 中</p><pre><code class="xml">&lt;filter&gt;    &lt;filter-name&gt;basicAuthenticationFilter&lt;/filter-name&gt;    &lt;filter-class&gt;com.dapeng.cloud.support.web.BasicAuthenticationFilter&lt;/filter-class&gt;    &lt;init-param&gt;      &lt;param-name&gt;username&lt;/param-name&gt;      &lt;param-value&gt;xxxx&lt;/param-value&gt;    &lt;/init-param&gt;    &lt;init-param&gt;      &lt;param-name&gt;password&lt;/param-name&gt;      &lt;param-value&gt;xxxx&lt;/param-value&gt;    &lt;/init-param&gt;  &lt;/filter&gt;  &lt;filter-mapping&gt;    &lt;filter-name&gt;basicAuthenticationFilter&lt;/filter-name&gt;    &lt;servlet-name&gt;HystrixMetricsStreamServlet&lt;/servlet-name&gt;  &lt;/filter-mapping&gt;</code></pre><p><code>BasicAuthenticationFilter</code> 源码:</p><pre><code class="java">package com.dapeng.cloud.support.web;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.util.StringTokenizer;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.codec.binary.Base64;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.util.StringUtils;public class BasicAuthenticationFilter implements Filter {  private static final Logger LOGGER = LoggerFactory.getLogger(BasicAuthenticationFilter.class);  private String username = &quot;&quot;;  private String password = &quot;&quot;;  private String realm = &quot;Protected&quot;;  public BasicAuthenticationFilter() {  }  public void init(FilterConfig filterConfig) throws ServletException {    this.username = filterConfig.getInitParameter(&quot;username&quot;);    this.password = filterConfig.getInitParameter(&quot;password&quot;);    String paramRealm = filterConfig.getInitParameter(&quot;realm&quot;);    if (StringUtils.hasText(paramRealm)) {      this.realm = paramRealm;    }  }  public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {    HttpServletRequest request = (HttpServletRequest)servletRequest;    HttpServletResponse response = (HttpServletResponse)servletResponse;    String authHeader = request.getHeader(&quot;Authorization&quot;);    if (authHeader != null) {      StringTokenizer st = new StringTokenizer(authHeader);      if (st.hasMoreTokens()) {        String basic = st.nextToken();        if (basic.equalsIgnoreCase(&quot;Basic&quot;)) {          try {            String credentials = new String(Base64.decodeBase64(st.nextToken()), &quot;UTF-8&quot;);            LOGGER.debug(&quot;Credentials: &quot; + credentials);            int p = credentials.indexOf(&quot;:&quot;);            if (p != -1) {              String _username = credentials.substring(0, p).trim();              String _password = credentials.substring(p + 1).trim();              if (this.username.equals(_username) &amp;&amp; this.password.equals(_password)) {                filterChain.doFilter(servletRequest, servletResponse);              } else {                this.unauthorized(response, &quot;Bad credentials&quot;);              }            } else {              this.unauthorized(response, &quot;Invalid authentication token&quot;);            }          } catch (UnsupportedEncodingException var13) {            throw new Error(&quot;Couldn&#39;t retrieve authentication&quot;, var13);          }        }      }    } else {      this.unauthorized(response);    }  }  public void destroy() {  }  private void unauthorized(HttpServletResponse response, String message) throws IOException {    response.setHeader(&quot;WWW-Authenticate&quot;, &quot;Basic realm=\&quot;&quot; + this.realm + &quot;\&quot;&quot;);    response.sendError(401, message);  }  private void unauthorized(HttpServletResponse response) throws IOException {    this.unauthorized(response, &quot;Unauthorized&quot;);  }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;增加依赖&quot;&gt;&lt;a href=&quot;#增加依赖&quot; class=&quot;headerlink&quot; title=&quot;增加依赖&quot;&gt;&lt;/a&gt;增加依赖&lt;/h2&gt;&lt;p&gt;pom文件中&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;xml&quot;&gt; &amp;lt;dependency&amp;gt;
  &amp;lt;gr
      
    
    </summary>
    
    
      <category term="hystrix" scheme="https://www.omingo.com/tags/hystrix/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://www.omingo.com/2019/05/07/hello-world/"/>
    <id>https://www.omingo.com/2019/05/07/hello-world/</id>
    <published>2019-05-07T06:07:43.724Z</published>
    <updated>2019-05-07T06:07:43.724Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><pre><code class="javascript">console.log(1)</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>本博客快捷键说明</title>
    <link href="https://www.omingo.com/2019/05/07/%E6%9C%AC%E5%8D%9A%E5%AE%A2%E5%BF%AB%E6%8D%B7%E9%94%AE%E8%AF%B4%E6%98%8E/"/>
    <id>https://www.omingo.com/2019/05/07/本博客快捷键说明/</id>
    <published>2019-05-07T02:51:36.000Z</published>
    <updated>2019-05-07T02:54:51.254Z</updated>
    
    <content type="html"><![CDATA[<p>快捷键为vim风格的。按键可能与vimium（chrome插件）的快捷键有冲突，插件设置屏蔽掉此站的快捷键即可</p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><h3 id="搜索框"><a href="#搜索框" class="headerlink" title="搜索框"></a>搜索框</h3><table><thead><tr><th style="text-align:left">Key</th><th style="text-align:left">Descption</th></tr></thead><tbody><tr><td style="text-align:left">ESC</td><td style="text-align:left">1.如果输入框有内容，清除内容<br>2.如果输入框无内容，失去焦点</td></tr><tr><td style="text-align:left">i/I</td><td style="text-align:left">获取焦点</td></tr><tr><td style="text-align:left">下</td><td style="text-align:left">向下选择文章</td></tr><tr><td style="text-align:left">上</td><td style="text-align:left">向上选择文章</td></tr><tr><td style="text-align:left">回车</td><td style="text-align:left">打开当前选中的文章，若没有，则默认打开第一个</td></tr></tbody></table><h3 id="全局"><a href="#全局" class="headerlink" title="全局"></a>全局</h3><table><thead><tr><th style="text-align:left">Key</th><th style="text-align:left">Descption</th></tr></thead><tbody><tr><td style="text-align:left">s/S</td><td style="text-align:left">全屏/取消全屏</td></tr><tr><td style="text-align:left">w/W</td><td style="text-align:left">打开/关闭文章目录</td></tr><tr><td style="text-align:left">j/J</td><td style="text-align:left">向下滑动</td></tr><tr><td style="text-align:left">k/K</td><td style="text-align:left">向上滑动</td></tr><tr><td style="text-align:left">gg/GG</td><td style="text-align:left">到最顶端</td></tr><tr><td style="text-align:left">shift+G/g</td><td style="text-align:left">到最下端</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;快捷键为vim风格的。按键可能与vimium（chrome插件）的快捷键有冲突，插件设置屏蔽掉此站的快捷键即可&lt;/p&gt;
&lt;h2 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h2&gt;&lt;h3 id=&quot;搜索
      
    
    </summary>
    
    
      <category term="快捷键" scheme="https://www.omingo.com/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    
  </entry>
  
</feed>
